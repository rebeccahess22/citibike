{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d1e0df",
   "metadata": {},
   "source": [
    "# CitiBike Data Analysis\n",
    "\n",
    "I am going to be walking through data analysis of citibike data. This file will include all intermediate steps in the process highlighting the decisions necessary to progress in data analysis. Those decisions include data cleaning, trimming, and data cleaning. After we have the date put together, we will start some feature generation and run a predictive model. After I have run a predictive model I will move on to creating a dashboard with my findings. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3be5c9",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e6d94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rebeccahess/Documents/projects/data_analytics/citibike\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/rebeccahess/Documents/projects/data_analytics/citibike')\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83777d",
   "metadata": {},
   "source": [
    "## File management "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd7e29",
   "metadata": {},
   "source": [
    "### Unzip the files that I downloaded from the internet:\n",
    "The way that the files were zipped varies, so I decided to write a recursive function to go deeper into the folders to pull out the csv's. It takes like 2 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68964365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Folder: /Users/rebeccahess/Documents/projects/data_analytics/citibike\n",
      "Final Destination: /Users/rebeccahess/Documents/projects/data_analytics/citibike/data\n",
      "Beginning File Loop\n",
      "File: 202408-citibike-tripdata\n",
      "Moving into Folder: 202408-citibike-tripdata\n",
      "Starting Folder: /Users/rebeccahess/Documents/projects/data_analytics/citibike/202408-citibike-tripdata\n",
      "Final Destination: /Users/rebeccahess/Documents/projects/data_analytics/citibike/data\n",
      "Beginning File Loop\n",
      "File: 202408-citibike-tripdata_3.csv\n",
      "Moving: 202408-citibike-tripdata_3.csv\n",
      "File: 202408-citibike-tripdata_2.csv\n",
      "Moving: 202408-citibike-tripdata_2.csv\n",
      "File: 202408-citibike-tripdata_1.csv\n",
      "Moving: 202408-citibike-tripdata_1.csv\n",
      "File: 202408-citibike-tripdata_5.csv\n",
      "Moving: 202408-citibike-tripdata_5.csv\n",
      "File: 202408-citibike-tripdata_4.csv\n",
      "Moving: 202408-citibike-tripdata_4.csv\n",
      "File: .DS_Store\n",
      "File: Untitled-1.ipynb\n",
      "File: 2023-citibike-tripdata\n",
      "Moving into Folder: 2023-citibike-tripdata\n",
      "Starting Folder: /Users/rebeccahess/Documents/projects/data_analytics/citibike/2023-citibike-tripdata\n",
      "Final Destination: /Users/rebeccahess/Documents/projects/data_analytics/citibike/data\n",
      "Beginning File Loop\n",
      "File: .DS_Store\n",
      "File: 202306-citibike-tripdata_3.csv\n",
      "Moving: 202306-citibike-tripdata_3.csv\n",
      "File: 202306-citibike-tripdata_1.csv\n",
      "Moving: 202306-citibike-tripdata_1.csv\n",
      "File: 202306-citibike-tripdata_4.csv\n",
      "Moving: 202306-citibike-tripdata_4.csv\n",
      "File: 202302-citibike-tripdata_2.csv\n",
      "Moving: 202302-citibike-tripdata_2.csv\n",
      "File: 202302-citibike-tripdata_1.csv\n",
      "Moving: 202302-citibike-tripdata_1.csv\n",
      "File: 202304-citibike-tripdata_3.csv\n",
      "Moving: 202304-citibike-tripdata_3.csv\n",
      "File: 202304-citibike-tripdata_2.csv\n",
      "Moving: 202304-citibike-tripdata_2.csv\n",
      "File: 202304-citibike-tripdata_1.csv\n",
      "Moving: 202304-citibike-tripdata_1.csv\n",
      "File: 202303-citibike-tripdata_1.csv\n",
      "Moving: 202303-citibike-tripdata_1.csv\n",
      "File: 202310-citibike-tripdata_3.csv\n",
      "Moving: 202310-citibike-tripdata_3.csv\n",
      "File: 202310-citibike-tripdata_2.csv\n",
      "Moving: 202310-citibike-tripdata_2.csv\n",
      "File: 202308-citibike-tripdata_4.csv\n",
      "Moving: 202308-citibike-tripdata_4.csv\n",
      "File: 202303-citibike-tripdata_2.csv\n",
      "Moving: 202303-citibike-tripdata_2.csv\n",
      "File: 202310-citibike-tripdata_1.csv\n",
      "Moving: 202310-citibike-tripdata_1.csv\n",
      "File: 202303-citibike-tripdata_3.csv\n",
      "Moving: 202303-citibike-tripdata_3.csv\n",
      "File: 202308-citibike-tripdata_1.csv\n",
      "Moving: 202308-citibike-tripdata_1.csv\n",
      "File: 202310-citibike-tripdata_4.csv\n",
      "Moving: 202310-citibike-tripdata_4.csv\n",
      "File: 202307-citibike-tripdata_1.csv\n",
      "Moving: 202307-citibike-tripdata_1.csv\n",
      "File: 202308-citibike-tripdata_2.csv\n",
      "Moving: 202308-citibike-tripdata_2.csv\n",
      "File: 202307-citibike-tripdata_3.csv\n",
      "Moving: 202307-citibike-tripdata_3.csv\n",
      "File: 202307-citibike-tripdata_2.csv\n",
      "Moving: 202307-citibike-tripdata_2.csv\n",
      "File: 202308-citibike-tripdata_3.csv\n",
      "Moving: 202308-citibike-tripdata_3.csv\n",
      "File: 202407-citibike-tripdata\n",
      "Moving into Folder: 202407-citibike-tripdata\n",
      "Starting Folder: /Users/rebeccahess/Documents/projects/data_analytics/citibike/202407-citibike-tripdata\n",
      "Final Destination: /Users/rebeccahess/Documents/projects/data_analytics/citibike/data\n",
      "Beginning File Loop\n",
      "File: 202407-citibike-tripdata_2.csv\n",
      "Moving: 202407-citibike-tripdata_2.csv\n",
      "File: 202407-citibike-tripdata_3.csv\n",
      "Moving: 202407-citibike-tripdata_3.csv\n",
      "File: 202407-citibike-tripdata_1.csv\n",
      "Moving: 202407-citibike-tripdata_1.csv\n",
      "File: 202407-citibike-tripdata_4.csv\n",
      "Moving: 202407-citibike-tripdata_4.csv\n",
      "File: 202407-citibike-tripdata_5.csv\n",
      "Moving: 202407-citibike-tripdata_5.csv\n",
      "File: data\n",
      "Moving into Folder: data\n",
      "Starting Folder: /Users/rebeccahess/Documents/projects/data_analytics/citibike/data\n",
      "Final Destination: /Users/rebeccahess/Documents/projects/data_analytics/citibike/data\n",
      "Beginning File Loop\n",
      "File: 201706-citibike-tripdata.csv_1.csv\n",
      "Moving: 201706-citibike-tripdata.csv_1.csv\n",
      "File: 202405-citibike-tripdata_3.csv\n",
      "Moving: 202405-citibike-tripdata_3.csv\n",
      "File: 202109-citibike-tripdata_3.csv\n",
      "Moving: 202109-citibike-tripdata_3.csv\n",
      "File: 202106-citibike-tripdata_2.csv\n",
      "Moving: 202106-citibike-tripdata_2.csv\n",
      "File: 201908-citibike-tripdata_1.csv\n",
      "Moving: 201908-citibike-tripdata_1.csv\n",
      "File: 202312-citibike-tripdata_2.csv\n",
      "Moving: 202312-citibike-tripdata_2.csv\n",
      "File: ._201801-citibike-tripdata.csv\n",
      "Moving: ._201801-citibike-tripdata.csv\n",
      "File: 202208-citibike-tripdata_3.csv\n",
      "Moving: 202208-citibike-tripdata_3.csv\n",
      "File: 202207-citibike-tripdata_2.csv\n",
      "Moving: 202207-citibike-tripdata_2.csv\n",
      "File: 201710-citibike-tripdata.csv_1.csv\n",
      "Moving: 201710-citibike-tripdata.csv_1.csv\n",
      "File: 201610-citibike-tripdata_1.csv\n",
      "Moving: 201610-citibike-tripdata_1.csv\n",
      "File: 202207-citibike-tripdata_3.csv\n",
      "Moving: 202207-citibike-tripdata_3.csv\n",
      "File: 202301-citibike-tripdata_1.csv\n",
      "Moving: 202301-citibike-tripdata_1.csv\n",
      "File: 202208-citibike-tripdata_2.csv\n",
      "Moving: 202208-citibike-tripdata_2.csv\n",
      "File: 201812-citibike-tripdata_1.csv\n",
      "Moving: 201812-citibike-tripdata_1.csv\n",
      "File: 202312-citibike-tripdata_3.csv\n",
      "Moving: 202312-citibike-tripdata_3.csv\n",
      "File: 201907-citibike-tripdata_1.csv\n",
      "Moving: 201907-citibike-tripdata_1.csv\n",
      "File: 201809-citibike-tripdata.csv\n",
      "Moving: 201809-citibike-tripdata.csv\n",
      "File: 202106-citibike-tripdata_3.csv\n",
      "Moving: 202106-citibike-tripdata_3.csv\n",
      "File: 202405-citibike-tripdata_2.csv\n",
      "Moving: 202405-citibike-tripdata_2.csv\n",
      "File: 202109-citibike-tripdata_2.csv\n",
      "Moving: 202109-citibike-tripdata_2.csv\n",
      "File: ._202404-citibike-tripdata.csv\n",
      "Moving: ._202404-citibike-tripdata.csv\n",
      "File: 201706-citibike-tripdata.csv_2.csv\n",
      "Moving: 201706-citibike-tripdata.csv_2.csv\n",
      "File: ._201809-citibike-tripdata.csv\n",
      "Moving: ._201809-citibike-tripdata.csv\n",
      "File: 202404-citibike-tripdata.csv\n",
      "Moving: 202404-citibike-tripdata.csv\n",
      "File: 202106-citibike-tripdata_1.csv\n",
      "Moving: 202106-citibike-tripdata_1.csv\n",
      "File: 202305-citibike-tripdata_4.csv\n",
      "Moving: 202305-citibike-tripdata_4.csv\n",
      "File: 201801-citibike-tripdata_1.csv\n",
      "Moving: 201801-citibike-tripdata_1.csv\n",
      "File: 201908-citibike-tripdata_2.csv\n",
      "Moving: 201908-citibike-tripdata_2.csv\n",
      "File: 201907-citibike-tripdata_3.csv\n",
      "Moving: 201907-citibike-tripdata_3.csv\n",
      "File: 201603-citibike-tripdata_1.csv\n",
      "Moving: 201603-citibike-tripdata_1.csv\n",
      "File: 202312-citibike-tripdata_1.csv\n",
      "Moving: 202312-citibike-tripdata_1.csv\n",
      "File: 201703-citibike-tripdata.csv_1.csv\n",
      "Moving: 201703-citibike-tripdata.csv_1.csv\n",
      "File: 202207-citibike-tripdata_1.csv\n",
      "Moving: 202207-citibike-tripdata_1.csv\n",
      "File: 201610-citibike-tripdata_2.csv\n",
      "Moving: 201610-citibike-tripdata_2.csv\n",
      "File: 201710-citibike-tripdata.csv_2.csv\n",
      "Moving: 201710-citibike-tripdata.csv_2.csv\n",
      "File: 202208-citibike-tripdata_1.csv\n",
      "Moving: 202208-citibike-tripdata_1.csv\n",
      "File: 202301-citibike-tripdata_2.csv\n",
      "Moving: 202301-citibike-tripdata_2.csv\n",
      "File: 201812-citibike-tripdata_2.csv\n",
      "Moving: 201812-citibike-tripdata_2.csv\n",
      "File: 201907-citibike-tripdata_2.csv\n",
      "Moving: 201907-citibike-tripdata_2.csv\n",
      "File: 201908-citibike-tripdata_3.csv\n",
      "Moving: 201908-citibike-tripdata_3.csv\n",
      "File: 201801-citibike-tripdata.csv\n",
      "Moving: 201801-citibike-tripdata.csv\n",
      "File: 202109-citibike-tripdata_1.csv\n",
      "Moving: 202109-citibike-tripdata_1.csv\n",
      "File: 202405-citibike-tripdata_1.csv\n",
      "Moving: 202405-citibike-tripdata_1.csv\n",
      "File: 201903-citibike-tripdata_1.csv\n",
      "Moving: 201903-citibike-tripdata_1.csv\n",
      "File: 202210-citibike-tripdata_1.csv\n",
      "Moving: 202210-citibike-tripdata_1.csv\n",
      "File: 201608-citibike-tripdata_2.csv\n",
      "Moving: 201608-citibike-tripdata_2.csv\n",
      "File: 202106-citibike-tripdata_4.csv\n",
      "Moving: 202106-citibike-tripdata_4.csv\n",
      "File: 201910-citibike-tripdata_3.csv\n",
      "Moving: 201910-citibike-tripdata_3.csv\n",
      "File: 202405-citibike-tripdata_5.csv\n",
      "Moving: 202405-citibike-tripdata_5.csv\n",
      "File: 202305-citibike-tripdata_1.csv\n",
      "Moving: 202305-citibike-tripdata_1.csv\n",
      "File: 202111-citibike-tripdata_1.csv\n",
      "Moving: 202111-citibike-tripdata_1.csv\n",
      "File: .DS_Store\n",
      "File: 202004-citibike-tripdata_1.csv\n",
      "Moving: 202004-citibike-tripdata_1.csv\n",
      "File: 202207-citibike-tripdata_4.csv\n",
      "Moving: 202207-citibike-tripdata_4.csv\n",
      "File: 202208-citibike-tripdata_4.csv\n",
      "Moving: 202208-citibike-tripdata_4.csv\n",
      "File: 201709-citibike-tripdata.csv_2.csv\n",
      "Moving: 201709-citibike-tripdata.csv_2.csv\n",
      "File: 202412-citibike-tripdata_1.csv\n",
      "Moving: 202412-citibike-tripdata_1.csv\n",
      "File: 202203-citibike-tripdata_2.csv\n",
      "Moving: 202203-citibike-tripdata_2.csv\n",
      "File: 202405-citibike-tripdata_4.csv\n",
      "Moving: 202405-citibike-tripdata_4.csv\n",
      "File: 202109-citibike-tripdata_4.csv\n",
      "Moving: 202109-citibike-tripdata_4.csv\n",
      "File: 201910-citibike-tripdata_2.csv\n",
      "Moving: 201910-citibike-tripdata_2.csv\n",
      "File: 201607-citibike-tripdata_2.csv\n",
      "Moving: 201607-citibike-tripdata_2.csv\n",
      "File: ._201803-citibike-tripdata.csv\n",
      "Moving: ._201803-citibike-tripdata.csv\n",
      "File: 201805-citibike-tripdata_2.csv\n",
      "Moving: 201805-citibike-tripdata_2.csv\n",
      "File: 201903-citibike-tripdata_2.csv\n",
      "Moving: 201903-citibike-tripdata_2.csv\n",
      "File: 202210-citibike-tripdata_2.csv\n",
      "Moving: 202210-citibike-tripdata_2.csv\n",
      "File: 201608-citibike-tripdata_1.csv\n",
      "Moving: 201608-citibike-tripdata_1.csv\n",
      "File: 201803-citibike-tripdata.csv\n",
      "Moving: 201803-citibike-tripdata.csv\n",
      "File: 202305-citibike-tripdata_2.csv\n",
      "Moving: 202305-citibike-tripdata_2.csv\n",
      "File: 202111-citibike-tripdata_2.csv\n",
      "Moving: 202111-citibike-tripdata_2.csv\n",
      "File: 202412-citibike-tripdata_3.csv\n",
      "Moving: 202412-citibike-tripdata_3.csv\n",
      "File: 202102-citibike-tripdata_1.csv\n",
      "Moving: 202102-citibike-tripdata_1.csv\n",
      "File: 201709-citibike-tripdata.csv_1.csv\n",
      "Moving: 201709-citibike-tripdata.csv_1.csv\n",
      "File: 202412-citibike-tripdata_2.csv\n",
      "Moving: 202412-citibike-tripdata_2.csv\n",
      "File: 202111-citibike-tripdata_3.csv\n",
      "Moving: 202111-citibike-tripdata_3.csv\n",
      "File: 202203-citibike-tripdata_1.csv\n",
      "Moving: 202203-citibike-tripdata_1.csv\n",
      "File: 202305-citibike-tripdata_3.csv\n",
      "Moving: 202305-citibike-tripdata_3.csv\n",
      "File: 201910-citibike-tripdata_1.csv\n",
      "Moving: 201910-citibike-tripdata_1.csv\n",
      "File: 202210-citibike-tripdata_3.csv\n",
      "Moving: 202210-citibike-tripdata_3.csv\n",
      "File: 201607-citibike-tripdata_1.csv\n",
      "Moving: 201607-citibike-tripdata_1.csv\n",
      "File: 201805-citibike-tripdata_1.csv\n",
      "Moving: 201805-citibike-tripdata_1.csv\n",
      "File: 202306-citibike-tripdata_2.csv\n",
      "Moving: 202306-citibike-tripdata_2.csv\n",
      "File: 201707-citibike-tripdata.csv_2.csv\n",
      "Moving: 201707-citibike-tripdata.csv_2.csv\n",
      "File: 202309-citibike-tripdata_3.csv\n",
      "Moving: 202309-citibike-tripdata_3.csv\n",
      "File: 202503-citibike-tripdata.csv\n",
      "Moving: 202503-citibike-tripdata.csv\n",
      "File: 201809-citibike-tripdata_1.csv\n",
      "Moving: 201809-citibike-tripdata_1.csv\n",
      "File: 202007-citibike-tripdata_2.csv\n",
      "Moving: 202007-citibike-tripdata_2.csv\n",
      "File: 202008-citibike-tripdata_3.csv\n",
      "Moving: 202008-citibike-tripdata_3.csv\n",
      "File: 202504-citibike-tripdata_3.csv\n",
      "Moving: 202504-citibike-tripdata_3.csv\n",
      "File: 201702-citibike-tripdata.csv_1.csv\n",
      "Moving: 201702-citibike-tripdata.csv_1.csv\n",
      "File: 202112-citibike-tripdata_2.csv\n",
      "Moving: 202112-citibike-tripdata_2.csv\n",
      "File: 202411-citibike-tripdata_3.csv\n",
      "Moving: 202411-citibike-tripdata_3.csv\n",
      "File: 202411-citibike-tripdata_2.csv\n",
      "Moving: 202411-citibike-tripdata_2.csv\n",
      "File: 201805-citibike-tripdata.csv\n",
      "Moving: 201805-citibike-tripdata.csv\n",
      "File: 201711-citibike-tripdata.csv_2.csv\n",
      "Moving: 201711-citibike-tripdata.csv_2.csv\n",
      "File: 202008-citibike-tripdata_2.csv\n",
      "Moving: 202008-citibike-tripdata_2.csv\n",
      "File: 202504-citibike-tripdata_2.csv\n",
      "Moving: 202504-citibike-tripdata_2.csv\n",
      "File: 202101-citibike-tripdata_1.csv\n",
      "Moving: 202101-citibike-tripdata_1.csv\n",
      "File: 202007-citibike-tripdata_3.csv\n",
      "Moving: 202007-citibike-tripdata_3.csv\n",
      "File: 201806-citibike-tripdata_1.csv\n",
      "Moving: 201806-citibike-tripdata_1.csv\n",
      "File: 201604-citibike-tripdata_1.csv\n",
      "Moving: 201604-citibike-tripdata_1.csv\n",
      "File: 202309-citibike-tripdata_2.csv\n",
      "Moving: 202309-citibike-tripdata_2.csv\n",
      "File: 202306-citibike-tripdata_3.csv\n",
      "Moving: 202306-citibike-tripdata_3.csv\n",
      "File: 202306-citibike-tripdata_1.csv\n",
      "Moving: 202306-citibike-tripdata_1.csv\n",
      "File: 201707-citibike-tripdata.csv_1.csv\n",
      "Moving: 201707-citibike-tripdata.csv_1.csv\n",
      "File: 202409-citibike-tripdata_4.csv\n",
      "Moving: 202409-citibike-tripdata_4.csv\n",
      "File: 202406-citibike-tripdata_5.csv\n",
      "Moving: 202406-citibike-tripdata_5.csv\n",
      "File: 201809-citibike-tripdata_2.csv\n",
      "Moving: 201809-citibike-tripdata_2.csv\n",
      "File: 202007-citibike-tripdata_1.csv\n",
      "Moving: 202007-citibike-tripdata_1.csv\n",
      "File: ._201805-citibike-tripdata.csv\n",
      "Moving: ._201805-citibike-tripdata.csv\n",
      "File: 202112-citibike-tripdata_1.csv\n",
      "Moving: 202112-citibike-tripdata_1.csv\n",
      "File: 202411-citibike-tripdata_1.csv\n",
      "Moving: 202411-citibike-tripdata_1.csv\n",
      "File: 201711-citibike-tripdata.csv_1.csv\n",
      "Moving: 201711-citibike-tripdata.csv_1.csv\n",
      "File: 202101-citibike-tripdata_2.csv\n",
      "Moving: 202101-citibike-tripdata_2.csv\n",
      "File: 202504-citibike-tripdata_1.csv\n",
      "Moving: 202504-citibike-tripdata_1.csv\n",
      "File: 202008-citibike-tripdata_1.csv\n",
      "Moving: 202008-citibike-tripdata_1.csv\n",
      "File: ._201804-citibike-tripdata_1.csv\n",
      "Moving: ._201804-citibike-tripdata_1.csv\n",
      "File: 201806-citibike-tripdata_2.csv\n",
      "Moving: 201806-citibike-tripdata_2.csv\n",
      "File: 201604-citibike-tripdata_2.csv\n",
      "Moving: 201604-citibike-tripdata_2.csv\n",
      "File: 202406-citibike-tripdata_4.csv\n",
      "Moving: 202406-citibike-tripdata_4.csv\n",
      "File: 202409-citibike-tripdata_5.csv\n",
      "Moving: 202409-citibike-tripdata_5.csv\n",
      "File: 202309-citibike-tripdata_1.csv\n",
      "Moving: 202309-citibike-tripdata_1.csv\n",
      "File: 202306-citibike-tripdata_4.csv\n",
      "Moving: 202306-citibike-tripdata_4.csv\n",
      "File: 201807-citibike-tripdata.csv\n",
      "Moving: 201807-citibike-tripdata.csv\n",
      "File: 202105-citibike-tripdata_1.csv\n",
      "Moving: 202105-citibike-tripdata_1.csv\n",
      "File: 202409-citibike-tripdata_1.csv\n",
      "Moving: 202409-citibike-tripdata_1.csv\n",
      "File: 202010-citibike-tripdata_1.csv\n",
      "Moving: 202010-citibike-tripdata_1.csv\n",
      "File: 202204-citibike-tripdata_1.csv\n",
      "Moving: 202204-citibike-tripdata_1.csv\n",
      "File: 201811-citibike-tripdata.csv\n",
      "Moving: 201811-citibike-tripdata.csv\n",
      "File: 202311-citibike-tripdata_1.csv\n",
      "Moving: 202311-citibike-tripdata_1.csv\n",
      "File: 201802-citibike-tripdata_1.csv\n",
      "Moving: 201802-citibike-tripdata_1.csv\n",
      "File: 201904-citibike-tripdata_2.csv\n",
      "Moving: 201904-citibike-tripdata_2.csv\n",
      "File: 202402-citibike-tripdata.csv\n",
      "Moving: 202402-citibike-tripdata.csv\n",
      "File: 202411-citibike-tripdata_4.csv\n",
      "Moving: 202411-citibike-tripdata_4.csv\n",
      "File: 201811-citibike-tripdata_2.csv\n",
      "Moving: 201811-citibike-tripdata_2.csv\n",
      "File: 202504-citibike-tripdata_4.csv\n",
      "Moving: 202504-citibike-tripdata_4.csv\n",
      "File: 201708-citibike-tripdata.csv_1.csv\n",
      "Moving: 201708-citibike-tripdata.csv_1.csv\n",
      "File: 202302-citibike-tripdata_2.csv\n",
      "Moving: 202302-citibike-tripdata_2.csv\n",
      "File: 202003-citibike-tripdata_2.csv\n",
      "Moving: 202003-citibike-tripdata_2.csv\n",
      "File: 202406-citibike-tripdata_1.csv\n",
      "Moving: 202406-citibike-tripdata_1.csv\n",
      "File: 202309-citibike-tripdata_4.csv\n",
      "Moving: 202309-citibike-tripdata_4.csv\n",
      "File: 202406-citibike-tripdata_3.csv\n",
      "Moving: 202406-citibike-tripdata_3.csv\n",
      "File: 202409-citibike-tripdata_2.csv\n",
      "Moving: 202409-citibike-tripdata_2.csv\n",
      "File: 202105-citibike-tripdata_2.csv\n",
      "Moving: 202105-citibike-tripdata_2.csv\n",
      "File: 202010-citibike-tripdata_2.csv\n",
      "Moving: 202010-citibike-tripdata_2.csv\n",
      "File: 202204-citibike-tripdata_2.csv\n",
      "Moving: 202204-citibike-tripdata_2.csv\n",
      "File: ._202402-citibike-tripdata.csv\n",
      "Moving: ._202402-citibike-tripdata.csv\n",
      "File: 202311-citibike-tripdata_2.csv\n",
      "Moving: 202311-citibike-tripdata_2.csv\n",
      "File: 201904-citibike-tripdata_1.csv\n",
      "Moving: 201904-citibike-tripdata_1.csv\n",
      "File: 202311-citibike-tripdata_3.csv\n",
      "Moving: 202311-citibike-tripdata_3.csv\n",
      "File: 201811-citibike-tripdata_1.csv\n",
      "Moving: 201811-citibike-tripdata_1.csv\n",
      "File: 202204-citibike-tripdata_3.csv\n",
      "Moving: 202204-citibike-tripdata_3.csv\n",
      "File: ._201811-citibike-tripdata.csv\n",
      "Moving: ._201811-citibike-tripdata.csv\n",
      "File: 202302-citibike-tripdata_1.csv\n",
      "Moving: 202302-citibike-tripdata_1.csv\n",
      "File: 201708-citibike-tripdata.csv_2.csv\n",
      "Moving: 201708-citibike-tripdata.csv_2.csv\n",
      "File: 202010-citibike-tripdata_3.csv\n",
      "Moving: 202010-citibike-tripdata_3.csv\n",
      "File: ._201807-citibike-tripdata.csv\n",
      "Moving: ._201807-citibike-tripdata.csv\n",
      "File: 202409-citibike-tripdata_3.csv\n",
      "Moving: 202409-citibike-tripdata_3.csv\n",
      "File: 202105-citibike-tripdata_3.csv\n",
      "Moving: 202105-citibike-tripdata_3.csv\n",
      "File: 202406-citibike-tripdata_2.csv\n",
      "Moving: 202406-citibike-tripdata_2.csv\n",
      "File: 202003-citibike-tripdata_1.csv\n",
      "Moving: 202003-citibike-tripdata_1.csv\n",
      "File: 202211-citibike-tripdata_3.csv\n",
      "Moving: 202211-citibike-tripdata_3.csv\n",
      "File: 201606-citibike-tripdata_1.csv\n",
      "Moving: 201606-citibike-tripdata_1.csv\n",
      "File: 201804-citibike-tripdata_1.csv\n",
      "Moving: 201804-citibike-tripdata_1.csv\n",
      "File: 202202-citibike-tripdata_1.csv\n",
      "Moving: 202202-citibike-tripdata_1.csv\n",
      "File: 202304-citibike-tripdata_3.csv\n",
      "Moving: 202304-citibike-tripdata_3.csv\n",
      "File: ._202409-citibike-tripdata_5.csv\n",
      "Moving: ._202409-citibike-tripdata_5.csv\n",
      "File: 201911-citibike-tripdata_1.csv\n",
      "Moving: 201911-citibike-tripdata_1.csv\n",
      "File: ._201808-citibike-tripdata.csv\n",
      "Moving: ._201808-citibike-tripdata.csv\n",
      "File: 202110-citibike-tripdata_3.csv\n",
      "Moving: 202110-citibike-tripdata_3.csv\n",
      "File: 202103-citibike-tripdata_1.csv\n",
      "Moving: 202103-citibike-tripdata_1.csv\n",
      "File: 202005-citibike-tripdata_2.csv\n",
      "Moving: 202005-citibike-tripdata_2.csv\n",
      "File: 202110-citibike-tripdata_2.csv\n",
      "Moving: 202110-citibike-tripdata_2.csv\n",
      "File: ._202409-citibike-tripdata_4.csv\n",
      "Moving: ._202409-citibike-tripdata_4.csv\n",
      "File: 202304-citibike-tripdata_2.csv\n",
      "Moving: 202304-citibike-tripdata_2.csv\n",
      "File: 202211-citibike-tripdata_2.csv\n",
      "Moving: 202211-citibike-tripdata_2.csv\n",
      "File: 201609-citibike-tripdata_1.csv\n",
      "Moving: 201609-citibike-tripdata_1.csv\n",
      "File: 201606-citibike-tripdata_2.csv\n",
      "Moving: 201606-citibike-tripdata_2.csv\n",
      "File: 201804-citibike-tripdata_2.csv\n",
      "Moving: 201804-citibike-tripdata_2.csv\n",
      "File: 202202-citibike-tripdata_2.csv\n",
      "Moving: 202202-citibike-tripdata_2.csv\n",
      "File: 202108-citibike-tripdata_4.csv\n",
      "Moving: 202108-citibike-tripdata_4.csv\n",
      "File: 201911-citibike-tripdata_2.csv\n",
      "Moving: 201911-citibike-tripdata_2.csv\n",
      "File: 202209-citibike-tripdata_4.csv\n",
      "Moving: 202209-citibike-tripdata_4.csv\n",
      "File: 202103-citibike-tripdata_2.csv\n",
      "Moving: 202103-citibike-tripdata_2.csv\n",
      "File: 202005-citibike-tripdata_1.csv\n",
      "Moving: 202005-citibike-tripdata_1.csv\n",
      "File: 201808-citibike-tripdata.csv\n",
      "Moving: 201808-citibike-tripdata.csv\n",
      "File: 202206-citibike-tripdata_4.csv\n",
      "Moving: 202206-citibike-tripdata_4.csv\n",
      "File: 202110-citibike-tripdata_1.csv\n",
      "Moving: 202110-citibike-tripdata_1.csv\n",
      "File: 202107-citibike-tripdata_4.csv\n",
      "Moving: 202107-citibike-tripdata_4.csv\n",
      "File: 202304-citibike-tripdata_1.csv\n",
      "Moving: 202304-citibike-tripdata_1.csv\n",
      "File: 201902-citibike-tripdata_1.csv\n",
      "Moving: 201902-citibike-tripdata_1.csv\n",
      "File: 202211-citibike-tripdata_1.csv\n",
      "Moving: 202211-citibike-tripdata_1.csv\n",
      "File: 201609-citibike-tripdata_2.csv\n",
      "Moving: 201609-citibike-tripdata_2.csv\n",
      "File: 201704-citibike-tripdata.csv_1.csv\n",
      "Moving: 201704-citibike-tripdata.csv_1.csv\n",
      "File: 202502-citibike-tripdata_3.csv\n",
      "Moving: 202502-citibike-tripdata_3.csv\n",
      "File: 202001-citibike-tripdata_2.csv\n",
      "Moving: 202001-citibike-tripdata_2.csv\n",
      "File: ._202409-citibike-tripdata_3.csv\n",
      "Moving: ._202409-citibike-tripdata_3.csv\n",
      "File: 202108-citibike-tripdata_1.csv\n",
      "Moving: 202108-citibike-tripdata_1.csv\n",
      "File: 201906-citibike-tripdata_2.csv\n",
      "Moving: 201906-citibike-tripdata_2.csv\n",
      "File: 201909-citibike-tripdata_3.csv\n",
      "Moving: 201909-citibike-tripdata_3.csv\n",
      "File: 201611-citibike-tripdata_2.csv\n",
      "Moving: 201611-citibike-tripdata_2.csv\n",
      "File: 201802-citibike-tripdata.csv\n",
      "Moving: 201802-citibike-tripdata.csv\n",
      "File: 202209-citibike-tripdata_1.csv\n",
      "Moving: 202209-citibike-tripdata_1.csv\n",
      "File: 202206-citibike-tripdata_1.csv\n",
      "Moving: 202206-citibike-tripdata_1.csv\n",
      "File: 201909-citibike-tripdata_2.csv\n",
      "Moving: 201909-citibike-tripdata_2.csv\n",
      "File: 201906-citibike-tripdata_3.csv\n",
      "Moving: 201906-citibike-tripdata_3.csv\n",
      "File: 202110-citibike-tripdata_4.csv\n",
      "Moving: 202110-citibike-tripdata_4.csv\n",
      "File: 201602-citibike-tripdata_1.csv\n",
      "Moving: 201602-citibike-tripdata_1.csv\n",
      "File: 201712-citibike-tripdata.csv_1.csv\n",
      "Moving: 201712-citibike-tripdata.csv_1.csv\n",
      "File: ._202409-citibike-tripdata_2.csv\n",
      "Moving: ._202409-citibike-tripdata_2.csv\n",
      "File: 202107-citibike-tripdata_1.csv\n",
      "Moving: 202107-citibike-tripdata_1.csv\n",
      "File: 202502-citibike-tripdata_2.csv\n",
      "Moving: 202502-citibike-tripdata_2.csv\n",
      "File: 202012-citibike-tripdata_1.csv\n",
      "Moving: 202012-citibike-tripdata_1.csv\n",
      "File: 201704-citibike-tripdata.csv_2.csv\n",
      "Moving: 201704-citibike-tripdata.csv_2.csv\n",
      "File: 202107-citibike-tripdata_3.csv\n",
      "Moving: 202107-citibike-tripdata_3.csv\n",
      "File: 202108-citibike-tripdata_2.csv\n",
      "Moving: 202108-citibike-tripdata_2.csv\n",
      "File: 202001-citibike-tripdata_1.csv\n",
      "Moving: 202001-citibike-tripdata_1.csv\n",
      "File: 201701-citibike-tripdata.csv_1.csv\n",
      "Moving: 201701-citibike-tripdata.csv_1.csv\n",
      "File: 201906-citibike-tripdata_1.csv\n",
      "Moving: 201906-citibike-tripdata_1.csv\n",
      "File: 201611-citibike-tripdata_1.csv\n",
      "Moving: 201611-citibike-tripdata_1.csv\n",
      "File: 202206-citibike-tripdata_3.csv\n",
      "Moving: 202206-citibike-tripdata_3.csv\n",
      "File: 202209-citibike-tripdata_2.csv\n",
      "Moving: 202209-citibike-tripdata_2.csv\n",
      "File: 202209-citibike-tripdata_3.csv\n",
      "Moving: 202209-citibike-tripdata_3.csv\n",
      "File: 202206-citibike-tripdata_2.csv\n",
      "Moving: 202206-citibike-tripdata_2.csv\n",
      "File: 201909-citibike-tripdata_1.csv\n",
      "Moving: 201909-citibike-tripdata_1.csv\n",
      "File: ._201802-citibike-tripdata.csv\n",
      "Moving: ._201802-citibike-tripdata.csv\n",
      "File: ._202409-citibike-tripdata_1.csv\n",
      "Moving: ._202409-citibike-tripdata_1.csv\n",
      "File: 202108-citibike-tripdata_3.csv\n",
      "Moving: 202108-citibike-tripdata_3.csv\n",
      "File: 202502-citibike-tripdata_1.csv\n",
      "Moving: 202502-citibike-tripdata_1.csv\n",
      "File: 202107-citibike-tripdata_2.csv\n",
      "Moving: 202107-citibike-tripdata_2.csv\n",
      "File: 202012-citibike-tripdata_2.csv\n",
      "Moving: 202012-citibike-tripdata_2.csv\n",
      "File: 202104-citibike-tripdata_3.csv\n",
      "Moving: 202104-citibike-tripdata_3.csv\n",
      "File: 202408-citibike-tripdata_3.csv\n",
      "Moving: 202408-citibike-tripdata_3.csv\n",
      "File: 202002-citibike-tripdata_1.csv\n",
      "Moving: 202002-citibike-tripdata_1.csv\n",
      "File: 202407-citibike-tripdata_2.csv\n",
      "Moving: 202407-citibike-tripdata_2.csv\n",
      "File: ._201804-citibike-tripdata.csv\n",
      "Moving: ._201804-citibike-tripdata.csv\n",
      "File: 201810-citibike-tripdata_1.csv\n",
      "Moving: 201810-citibike-tripdata_1.csv\n",
      "File: 201612-citibike-tripdata_1.csv\n",
      "Moving: 201612-citibike-tripdata_1.csv\n",
      "File: 202205-citibike-tripdata_3.csv\n",
      "Moving: 202205-citibike-tripdata_3.csv\n",
      "File: 202303-citibike-tripdata_1.csv\n",
      "Moving: 202303-citibike-tripdata_1.csv\n",
      "File: ._201908-citibike-tripdata_3.csv\n",
      "Moving: ._201908-citibike-tripdata_3.csv\n",
      "File: 201905-citibike-tripdata_1.csv\n",
      "Moving: 201905-citibike-tripdata_1.csv\n",
      "File: ._201812-citibike-tripdata.csv\n",
      "Moving: ._201812-citibike-tripdata.csv\n",
      "File: 202310-citibike-tripdata_3.csv\n",
      "Moving: 202310-citibike-tripdata_3.csv\n",
      "File: ._202401-citibike-tripdata.csv\n",
      "Moving: ._202401-citibike-tripdata.csv\n",
      "File: 202310-citibike-tripdata_2.csv\n",
      "Moving: 202310-citibike-tripdata_2.csv\n",
      "File: 202410-citibike-tripdata_6.csv\n",
      "Moving: 202410-citibike-tripdata_6.csv\n",
      "File: 202205-citibike-tripdata_2.csv\n",
      "Moving: 202205-citibike-tripdata_2.csv\n",
      "File: 202011-citibike-tripdata_2.csv\n",
      "Moving: 202011-citibike-tripdata_2.csv\n",
      "File: 202407-citibike-tripdata_3.csv\n",
      "Moving: 202407-citibike-tripdata_3.csv\n",
      "File: 202104-citibike-tripdata_2.csv\n",
      "Moving: 202104-citibike-tripdata_2.csv\n",
      "File: 202408-citibike-tripdata_2.csv\n",
      "Moving: 202408-citibike-tripdata_2.csv\n",
      "File: 202501-citibike-tripdata_1.csv\n",
      "Moving: 202501-citibike-tripdata_1.csv\n",
      "File: 202501-citibike-tripdata_3.csv\n",
      "Moving: 202501-citibike-tripdata_3.csv\n",
      "File: 202407-citibike-tripdata_1.csv\n",
      "Moving: 202407-citibike-tripdata_1.csv\n",
      "File: 202002-citibike-tripdata_2.csv\n",
      "Moving: 202002-citibike-tripdata_2.csv\n",
      "File: 202308-citibike-tripdata_4.csv\n",
      "Moving: 202308-citibike-tripdata_4.csv\n",
      "File: 201810-citibike-tripdata_2.csv\n",
      "Moving: 201810-citibike-tripdata_2.csv\n",
      "File: 202401-citibike-tripdata.csv\n",
      "Moving: 202401-citibike-tripdata.csv\n",
      "File: 202303-citibike-tripdata_2.csv\n",
      "Moving: 202303-citibike-tripdata_2.csv\n",
      "File: 201905-citibike-tripdata_2.csv\n",
      "Moving: 201905-citibike-tripdata_2.csv\n",
      "File: 202410-citibike-tripdata_4.csv\n",
      "Moving: 202410-citibike-tripdata_4.csv\n",
      "File: 201601-citibike-tripdata_1.csv\n",
      "Moving: 201601-citibike-tripdata_1.csv\n",
      "File: 202310-citibike-tripdata_1.csv\n",
      "Moving: 202310-citibike-tripdata_1.csv\n",
      "File: 201803-citibike-tripdata_1.csv\n",
      "Moving: 201803-citibike-tripdata_1.csv\n",
      "File: 202410-citibike-tripdata_5.csv\n",
      "Moving: 202410-citibike-tripdata_5.csv\n",
      "File: 202303-citibike-tripdata_3.csv\n",
      "Moving: 202303-citibike-tripdata_3.csv\n",
      "File: 202205-citibike-tripdata_1.csv\n",
      "Moving: 202205-citibike-tripdata_1.csv\n",
      "File: 201812-citibike-tripdata.csv\n",
      "Moving: 201812-citibike-tripdata.csv\n",
      "File: 201804-citibike-tripdata.csv\n",
      "Moving: 201804-citibike-tripdata.csv\n",
      "File: 202011-citibike-tripdata_1.csv\n",
      "Moving: 202011-citibike-tripdata_1.csv\n",
      "File: 202307-citibike-tripdata_4.csv\n",
      "Moving: 202307-citibike-tripdata_4.csv\n",
      "File: 202501-citibike-tripdata_2.csv\n",
      "Moving: 202501-citibike-tripdata_2.csv\n",
      "File: 202408-citibike-tripdata_1.csv\n",
      "Moving: 202408-citibike-tripdata_1.csv\n",
      "File: 202104-citibike-tripdata_1.csv\n",
      "Moving: 202104-citibike-tripdata_1.csv\n",
      "File: 202407-citibike-tripdata_4.csv\n",
      "Moving: 202407-citibike-tripdata_4.csv\n",
      "File: 202408-citibike-tripdata_5.csv\n",
      "Moving: 202408-citibike-tripdata_5.csv\n",
      "File: ._202403-citibike-tripdata.csv\n",
      "Moving: ._202403-citibike-tripdata.csv\n",
      "File: 202308-citibike-tripdata_1.csv\n",
      "Moving: 202308-citibike-tripdata_1.csv\n",
      "File: 202201-citibike-tripdata_2.csv\n",
      "Moving: 202201-citibike-tripdata_2.csv\n",
      "File: 201807-citibike-tripdata_2.csv\n",
      "Moving: 201807-citibike-tripdata_2.csv\n",
      "File: 201705-citibike-tripdata.csv_2.csv\n",
      "Moving: 201705-citibike-tripdata.csv_2.csv\n",
      "File: 201605-citibike-tripdata_2.csv\n",
      "Moving: 201605-citibike-tripdata_2.csv\n",
      "File: 202009-citibike-tripdata_1.csv\n",
      "Moving: 202009-citibike-tripdata_1.csv\n",
      "File: 202410-citibike-tripdata_1.csv\n",
      "Moving: 202410-citibike-tripdata_1.csv\n",
      "File: 202310-citibike-tripdata_4.csv\n",
      "Moving: 202310-citibike-tripdata_4.csv\n",
      "File: ._201806-citibike-tripdata.csv\n",
      "Moving: ._201806-citibike-tripdata.csv\n",
      "File: 202006-citibike-tripdata_1.csv\n",
      "Moving: 202006-citibike-tripdata_1.csv\n",
      "File: 202212-citibike-tripdata_1.csv\n",
      "Moving: 202212-citibike-tripdata_1.csv\n",
      "File: 201901-citibike-tripdata_1.csv\n",
      "Moving: 201901-citibike-tripdata_1.csv\n",
      "File: 201808-citibike-tripdata_2.csv\n",
      "Moving: 201808-citibike-tripdata_2.csv\n",
      "File: 202307-citibike-tripdata_1.csv\n",
      "Moving: 202307-citibike-tripdata_1.csv\n",
      "File: ._201810-citibike-tripdata.csv\n",
      "Moving: ._201810-citibike-tripdata.csv\n",
      "File: 202408-citibike-tripdata_4.csv\n",
      "Moving: 202408-citibike-tripdata_4.csv\n",
      "File: 202407-citibike-tripdata_5.csv\n",
      "Moving: 202407-citibike-tripdata_5.csv\n",
      "File: 201912-citibike-tripdata_1.csv\n",
      "Moving: 201912-citibike-tripdata_1.csv\n",
      "File: 202201-citibike-tripdata_1.csv\n",
      "Moving: 202201-citibike-tripdata_1.csv\n",
      "File: 202308-citibike-tripdata_2.csv\n",
      "Moving: 202308-citibike-tripdata_2.csv\n",
      "File: 202307-citibike-tripdata_3.csv\n",
      "Moving: 202307-citibike-tripdata_3.csv\n",
      "File: 201810-citibike-tripdata.csv\n",
      "Moving: 201810-citibike-tripdata.csv\n",
      "File: 201807-citibike-tripdata_1.csv\n",
      "Moving: 201807-citibike-tripdata_1.csv\n",
      "File: 201705-citibike-tripdata.csv_1.csv\n",
      "Moving: 201705-citibike-tripdata.csv_1.csv\n",
      "File: 201605-citibike-tripdata_1.csv\n",
      "Moving: 201605-citibike-tripdata_1.csv\n",
      "File: 202009-citibike-tripdata_2.csv\n",
      "Moving: 202009-citibike-tripdata_2.csv\n",
      "File: 201806-citibike-tripdata.csv\n",
      "Moving: 201806-citibike-tripdata.csv\n",
      "File: 202410-citibike-tripdata_2.csv\n",
      "Moving: 202410-citibike-tripdata_2.csv\n",
      "File: 202410-citibike-tripdata_3.csv\n",
      "Moving: 202410-citibike-tripdata_3.csv\n",
      "File: 202006-citibike-tripdata_2.csv\n",
      "Moving: 202006-citibike-tripdata_2.csv\n",
      "File: 202009-citibike-tripdata_3.csv\n",
      "Moving: 202009-citibike-tripdata_3.csv\n",
      "File: 202403-citibike-tripdata.csv\n",
      "Moving: 202403-citibike-tripdata.csv\n",
      "File: 202212-citibike-tripdata_2.csv\n",
      "Moving: 202212-citibike-tripdata_2.csv\n",
      "File: 201808-citibike-tripdata_1.csv\n",
      "Moving: 201808-citibike-tripdata_1.csv\n",
      "File: 202307-citibike-tripdata_2.csv\n",
      "Moving: 202307-citibike-tripdata_2.csv\n",
      "File: 202308-citibike-tripdata_3.csv\n",
      "Moving: 202308-citibike-tripdata_3.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['201706-citibike-tripdata.csv_1.csv',\n",
       " '202405-citibike-tripdata_3.csv',\n",
       " '202109-citibike-tripdata_3.csv',\n",
       " '202106-citibike-tripdata_2.csv',\n",
       " '201908-citibike-tripdata_1.csv',\n",
       " '202312-citibike-tripdata_2.csv',\n",
       " '._201801-citibike-tripdata.csv',\n",
       " '202208-citibike-tripdata_3.csv',\n",
       " '202207-citibike-tripdata_2.csv',\n",
       " '201710-citibike-tripdata.csv_1.csv',\n",
       " '201610-citibike-tripdata_1.csv',\n",
       " '202207-citibike-tripdata_3.csv',\n",
       " '202301-citibike-tripdata_1.csv',\n",
       " '202208-citibike-tripdata_2.csv',\n",
       " '201812-citibike-tripdata_1.csv',\n",
       " '202312-citibike-tripdata_3.csv',\n",
       " '201907-citibike-tripdata_1.csv',\n",
       " '201809-citibike-tripdata.csv',\n",
       " '202106-citibike-tripdata_3.csv',\n",
       " '202405-citibike-tripdata_2.csv',\n",
       " '202109-citibike-tripdata_2.csv',\n",
       " '._202404-citibike-tripdata.csv',\n",
       " '201706-citibike-tripdata.csv_2.csv',\n",
       " '._201809-citibike-tripdata.csv',\n",
       " '202404-citibike-tripdata.csv',\n",
       " '202106-citibike-tripdata_1.csv',\n",
       " '202305-citibike-tripdata_4.csv',\n",
       " '201801-citibike-tripdata_1.csv',\n",
       " '201908-citibike-tripdata_2.csv',\n",
       " '201907-citibike-tripdata_3.csv',\n",
       " '201603-citibike-tripdata_1.csv',\n",
       " '202312-citibike-tripdata_1.csv',\n",
       " '201703-citibike-tripdata.csv_1.csv',\n",
       " '202207-citibike-tripdata_1.csv',\n",
       " '201610-citibike-tripdata_2.csv',\n",
       " '201710-citibike-tripdata.csv_2.csv',\n",
       " '202208-citibike-tripdata_1.csv',\n",
       " '202301-citibike-tripdata_2.csv',\n",
       " '201812-citibike-tripdata_2.csv',\n",
       " '201907-citibike-tripdata_2.csv',\n",
       " '201908-citibike-tripdata_3.csv',\n",
       " '201801-citibike-tripdata.csv',\n",
       " '202109-citibike-tripdata_1.csv',\n",
       " '202405-citibike-tripdata_1.csv',\n",
       " '201903-citibike-tripdata_1.csv',\n",
       " '202210-citibike-tripdata_1.csv',\n",
       " '201608-citibike-tripdata_2.csv',\n",
       " '202106-citibike-tripdata_4.csv',\n",
       " '201910-citibike-tripdata_3.csv',\n",
       " '202405-citibike-tripdata_5.csv',\n",
       " '202305-citibike-tripdata_1.csv',\n",
       " '202111-citibike-tripdata_1.csv',\n",
       " '.DS_Store',\n",
       " '202004-citibike-tripdata_1.csv',\n",
       " '202207-citibike-tripdata_4.csv',\n",
       " '202208-citibike-tripdata_4.csv',\n",
       " '201709-citibike-tripdata.csv_2.csv',\n",
       " '202412-citibike-tripdata_1.csv',\n",
       " '202203-citibike-tripdata_2.csv',\n",
       " '202405-citibike-tripdata_4.csv',\n",
       " '202109-citibike-tripdata_4.csv',\n",
       " '201910-citibike-tripdata_2.csv',\n",
       " '201607-citibike-tripdata_2.csv',\n",
       " '._201803-citibike-tripdata.csv',\n",
       " '201805-citibike-tripdata_2.csv',\n",
       " '201903-citibike-tripdata_2.csv',\n",
       " '202210-citibike-tripdata_2.csv',\n",
       " '201608-citibike-tripdata_1.csv',\n",
       " '201803-citibike-tripdata.csv',\n",
       " '202305-citibike-tripdata_2.csv',\n",
       " '202111-citibike-tripdata_2.csv',\n",
       " '202412-citibike-tripdata_3.csv',\n",
       " '202102-citibike-tripdata_1.csv',\n",
       " '201709-citibike-tripdata.csv_1.csv',\n",
       " '202412-citibike-tripdata_2.csv',\n",
       " '202111-citibike-tripdata_3.csv',\n",
       " '202203-citibike-tripdata_1.csv',\n",
       " '202305-citibike-tripdata_3.csv',\n",
       " '201910-citibike-tripdata_1.csv',\n",
       " '202210-citibike-tripdata_3.csv',\n",
       " '201607-citibike-tripdata_1.csv',\n",
       " '201805-citibike-tripdata_1.csv',\n",
       " '202306-citibike-tripdata_2.csv',\n",
       " '201707-citibike-tripdata.csv_2.csv',\n",
       " '202309-citibike-tripdata_3.csv',\n",
       " '202503-citibike-tripdata.csv',\n",
       " '201809-citibike-tripdata_1.csv',\n",
       " '202007-citibike-tripdata_2.csv',\n",
       " '202008-citibike-tripdata_3.csv',\n",
       " '202504-citibike-tripdata_3.csv',\n",
       " '201702-citibike-tripdata.csv_1.csv',\n",
       " '202112-citibike-tripdata_2.csv',\n",
       " '202411-citibike-tripdata_3.csv',\n",
       " '202411-citibike-tripdata_2.csv',\n",
       " '201805-citibike-tripdata.csv',\n",
       " '201711-citibike-tripdata.csv_2.csv',\n",
       " '202008-citibike-tripdata_2.csv',\n",
       " '202504-citibike-tripdata_2.csv',\n",
       " '202101-citibike-tripdata_1.csv',\n",
       " '202007-citibike-tripdata_3.csv',\n",
       " '201806-citibike-tripdata_1.csv',\n",
       " '201604-citibike-tripdata_1.csv',\n",
       " '202309-citibike-tripdata_2.csv',\n",
       " '202306-citibike-tripdata_3.csv',\n",
       " '202306-citibike-tripdata_1.csv',\n",
       " '201707-citibike-tripdata.csv_1.csv',\n",
       " '202409-citibike-tripdata_4.csv',\n",
       " '202406-citibike-tripdata_5.csv',\n",
       " '201809-citibike-tripdata_2.csv',\n",
       " '202007-citibike-tripdata_1.csv',\n",
       " '._201805-citibike-tripdata.csv',\n",
       " '202112-citibike-tripdata_1.csv',\n",
       " '202411-citibike-tripdata_1.csv',\n",
       " '201711-citibike-tripdata.csv_1.csv',\n",
       " '202101-citibike-tripdata_2.csv',\n",
       " '202504-citibike-tripdata_1.csv',\n",
       " '202008-citibike-tripdata_1.csv',\n",
       " '._201804-citibike-tripdata_1.csv',\n",
       " '201806-citibike-tripdata_2.csv',\n",
       " '201604-citibike-tripdata_2.csv',\n",
       " '202406-citibike-tripdata_4.csv',\n",
       " '202409-citibike-tripdata_5.csv',\n",
       " '202309-citibike-tripdata_1.csv',\n",
       " '202306-citibike-tripdata_4.csv',\n",
       " '201807-citibike-tripdata.csv',\n",
       " '202105-citibike-tripdata_1.csv',\n",
       " '202409-citibike-tripdata_1.csv',\n",
       " '202010-citibike-tripdata_1.csv',\n",
       " '202204-citibike-tripdata_1.csv',\n",
       " '201811-citibike-tripdata.csv',\n",
       " '202311-citibike-tripdata_1.csv',\n",
       " '201802-citibike-tripdata_1.csv',\n",
       " '201904-citibike-tripdata_2.csv',\n",
       " '202402-citibike-tripdata.csv',\n",
       " '202411-citibike-tripdata_4.csv',\n",
       " '201811-citibike-tripdata_2.csv',\n",
       " '202504-citibike-tripdata_4.csv',\n",
       " '201708-citibike-tripdata.csv_1.csv',\n",
       " '202302-citibike-tripdata_2.csv',\n",
       " '202003-citibike-tripdata_2.csv',\n",
       " '202406-citibike-tripdata_1.csv',\n",
       " '202309-citibike-tripdata_4.csv',\n",
       " '202406-citibike-tripdata_3.csv',\n",
       " '202409-citibike-tripdata_2.csv',\n",
       " '202105-citibike-tripdata_2.csv',\n",
       " '202010-citibike-tripdata_2.csv',\n",
       " '202204-citibike-tripdata_2.csv',\n",
       " '._202402-citibike-tripdata.csv',\n",
       " '202311-citibike-tripdata_2.csv',\n",
       " '201904-citibike-tripdata_1.csv',\n",
       " '202311-citibike-tripdata_3.csv',\n",
       " '201811-citibike-tripdata_1.csv',\n",
       " '202204-citibike-tripdata_3.csv',\n",
       " '._201811-citibike-tripdata.csv',\n",
       " '202302-citibike-tripdata_1.csv',\n",
       " '201708-citibike-tripdata.csv_2.csv',\n",
       " '202010-citibike-tripdata_3.csv',\n",
       " '._201807-citibike-tripdata.csv',\n",
       " '202409-citibike-tripdata_3.csv',\n",
       " '202105-citibike-tripdata_3.csv',\n",
       " '202406-citibike-tripdata_2.csv',\n",
       " '202003-citibike-tripdata_1.csv',\n",
       " '202211-citibike-tripdata_3.csv',\n",
       " '201606-citibike-tripdata_1.csv',\n",
       " '201804-citibike-tripdata_1.csv',\n",
       " '202202-citibike-tripdata_1.csv',\n",
       " '202304-citibike-tripdata_3.csv',\n",
       " '._202409-citibike-tripdata_5.csv',\n",
       " '201911-citibike-tripdata_1.csv',\n",
       " '._201808-citibike-tripdata.csv',\n",
       " '202110-citibike-tripdata_3.csv',\n",
       " '202103-citibike-tripdata_1.csv',\n",
       " '202005-citibike-tripdata_2.csv',\n",
       " '202110-citibike-tripdata_2.csv',\n",
       " '._202409-citibike-tripdata_4.csv',\n",
       " '202304-citibike-tripdata_2.csv',\n",
       " '202211-citibike-tripdata_2.csv',\n",
       " '201609-citibike-tripdata_1.csv',\n",
       " '201606-citibike-tripdata_2.csv',\n",
       " '201804-citibike-tripdata_2.csv',\n",
       " '202202-citibike-tripdata_2.csv',\n",
       " '202108-citibike-tripdata_4.csv',\n",
       " '201911-citibike-tripdata_2.csv',\n",
       " '202209-citibike-tripdata_4.csv',\n",
       " '202103-citibike-tripdata_2.csv',\n",
       " '202005-citibike-tripdata_1.csv',\n",
       " '201808-citibike-tripdata.csv',\n",
       " '202206-citibike-tripdata_4.csv',\n",
       " '202110-citibike-tripdata_1.csv',\n",
       " '202107-citibike-tripdata_4.csv',\n",
       " '202304-citibike-tripdata_1.csv',\n",
       " '201902-citibike-tripdata_1.csv',\n",
       " '202211-citibike-tripdata_1.csv',\n",
       " '201609-citibike-tripdata_2.csv',\n",
       " '201704-citibike-tripdata.csv_1.csv',\n",
       " '202502-citibike-tripdata_3.csv',\n",
       " '202001-citibike-tripdata_2.csv',\n",
       " '._202409-citibike-tripdata_3.csv',\n",
       " '202108-citibike-tripdata_1.csv',\n",
       " '201906-citibike-tripdata_2.csv',\n",
       " '201909-citibike-tripdata_3.csv',\n",
       " '201611-citibike-tripdata_2.csv',\n",
       " '201802-citibike-tripdata.csv',\n",
       " '202209-citibike-tripdata_1.csv',\n",
       " '202206-citibike-tripdata_1.csv',\n",
       " '201909-citibike-tripdata_2.csv',\n",
       " '201906-citibike-tripdata_3.csv',\n",
       " '202110-citibike-tripdata_4.csv',\n",
       " '201602-citibike-tripdata_1.csv',\n",
       " '201712-citibike-tripdata.csv_1.csv',\n",
       " '._202409-citibike-tripdata_2.csv',\n",
       " '202107-citibike-tripdata_1.csv',\n",
       " '202502-citibike-tripdata_2.csv',\n",
       " '202012-citibike-tripdata_1.csv',\n",
       " '201704-citibike-tripdata.csv_2.csv',\n",
       " '202107-citibike-tripdata_3.csv',\n",
       " '202108-citibike-tripdata_2.csv',\n",
       " '202001-citibike-tripdata_1.csv',\n",
       " '201701-citibike-tripdata.csv_1.csv',\n",
       " '201906-citibike-tripdata_1.csv',\n",
       " '201611-citibike-tripdata_1.csv',\n",
       " '202206-citibike-tripdata_3.csv',\n",
       " '202209-citibike-tripdata_2.csv',\n",
       " '202209-citibike-tripdata_3.csv',\n",
       " '202206-citibike-tripdata_2.csv',\n",
       " '201909-citibike-tripdata_1.csv',\n",
       " '._201802-citibike-tripdata.csv',\n",
       " '._202409-citibike-tripdata_1.csv',\n",
       " '202108-citibike-tripdata_3.csv',\n",
       " '202502-citibike-tripdata_1.csv',\n",
       " '202107-citibike-tripdata_2.csv',\n",
       " '202012-citibike-tripdata_2.csv',\n",
       " '202104-citibike-tripdata_3.csv',\n",
       " '202408-citibike-tripdata_3.csv',\n",
       " '202002-citibike-tripdata_1.csv',\n",
       " '202407-citibike-tripdata_2.csv',\n",
       " '._201804-citibike-tripdata.csv',\n",
       " '201810-citibike-tripdata_1.csv',\n",
       " '201612-citibike-tripdata_1.csv',\n",
       " '202205-citibike-tripdata_3.csv',\n",
       " '202303-citibike-tripdata_1.csv',\n",
       " '._201908-citibike-tripdata_3.csv',\n",
       " '201905-citibike-tripdata_1.csv',\n",
       " '._201812-citibike-tripdata.csv',\n",
       " '202310-citibike-tripdata_3.csv',\n",
       " '._202401-citibike-tripdata.csv',\n",
       " '202310-citibike-tripdata_2.csv',\n",
       " '202410-citibike-tripdata_6.csv',\n",
       " '202205-citibike-tripdata_2.csv',\n",
       " '202011-citibike-tripdata_2.csv',\n",
       " '202407-citibike-tripdata_3.csv',\n",
       " '202104-citibike-tripdata_2.csv',\n",
       " '202408-citibike-tripdata_2.csv',\n",
       " '202501-citibike-tripdata_1.csv',\n",
       " '202501-citibike-tripdata_3.csv',\n",
       " '202407-citibike-tripdata_1.csv',\n",
       " '202002-citibike-tripdata_2.csv',\n",
       " '202308-citibike-tripdata_4.csv',\n",
       " '201810-citibike-tripdata_2.csv',\n",
       " '202401-citibike-tripdata.csv',\n",
       " '202303-citibike-tripdata_2.csv',\n",
       " '201905-citibike-tripdata_2.csv',\n",
       " '202410-citibike-tripdata_4.csv',\n",
       " '201601-citibike-tripdata_1.csv',\n",
       " '202310-citibike-tripdata_1.csv',\n",
       " '201803-citibike-tripdata_1.csv',\n",
       " '202410-citibike-tripdata_5.csv',\n",
       " '202303-citibike-tripdata_3.csv',\n",
       " '202205-citibike-tripdata_1.csv',\n",
       " '201812-citibike-tripdata.csv',\n",
       " '201804-citibike-tripdata.csv',\n",
       " '202011-citibike-tripdata_1.csv',\n",
       " '202307-citibike-tripdata_4.csv',\n",
       " '202501-citibike-tripdata_2.csv',\n",
       " '202408-citibike-tripdata_1.csv',\n",
       " '202104-citibike-tripdata_1.csv',\n",
       " '202407-citibike-tripdata_4.csv',\n",
       " '202408-citibike-tripdata_5.csv',\n",
       " '._202403-citibike-tripdata.csv',\n",
       " '202308-citibike-tripdata_1.csv',\n",
       " '202201-citibike-tripdata_2.csv',\n",
       " '201807-citibike-tripdata_2.csv',\n",
       " '201705-citibike-tripdata.csv_2.csv',\n",
       " '201605-citibike-tripdata_2.csv',\n",
       " '202009-citibike-tripdata_1.csv',\n",
       " '202410-citibike-tripdata_1.csv',\n",
       " '202310-citibike-tripdata_4.csv',\n",
       " '._201806-citibike-tripdata.csv',\n",
       " '202006-citibike-tripdata_1.csv',\n",
       " '202212-citibike-tripdata_1.csv',\n",
       " '201901-citibike-tripdata_1.csv',\n",
       " '201808-citibike-tripdata_2.csv',\n",
       " '202307-citibike-tripdata_1.csv',\n",
       " '._201810-citibike-tripdata.csv',\n",
       " '202408-citibike-tripdata_4.csv',\n",
       " '202407-citibike-tripdata_5.csv',\n",
       " '201912-citibike-tripdata_1.csv',\n",
       " '202201-citibike-tripdata_1.csv',\n",
       " '202308-citibike-tripdata_2.csv',\n",
       " '202307-citibike-tripdata_3.csv',\n",
       " '201810-citibike-tripdata.csv',\n",
       " '201807-citibike-tripdata_1.csv',\n",
       " '201705-citibike-tripdata.csv_1.csv',\n",
       " '201605-citibike-tripdata_1.csv',\n",
       " '202009-citibike-tripdata_2.csv',\n",
       " '201806-citibike-tripdata.csv',\n",
       " '202410-citibike-tripdata_2.csv',\n",
       " '202410-citibike-tripdata_3.csv',\n",
       " '202006-citibike-tripdata_2.csv',\n",
       " '202009-citibike-tripdata_3.csv',\n",
       " '202403-citibike-tripdata.csv',\n",
       " '202212-citibike-tripdata_2.csv',\n",
       " '201808-citibike-tripdata_1.csv',\n",
       " '202307-citibike-tripdata_2.csv',\n",
       " '202308-citibike-tripdata_3.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import shutil \n",
    "import re \n",
    "\n",
    "#things i learned from chatgpt to make this recursive code work:\n",
    "# 1. its os.path.exists()\n",
    "# 2. os.path.isdir() confirms if the path is a directory\n",
    "# 3. you need the FULL path of the zip file to extract it\n",
    "# 4. moved the continue into the if statements for zip and csv files; some folders do not have the citibike name in them\n",
    "\n",
    "#create a directory to extract all of the data to \n",
    "if not os.path.exists('data'): os.makedirs('data')\n",
    "\n",
    "starting_folder = '/Users/rebeccahess/Documents/projects/data_analytics/citibike'\n",
    "#change the working directory to the directory where the zip files are located\n",
    "final_destination = os.path.join(starting_folder, 'data')\n",
    "\n",
    "#making a function to do some recursion to unzip the files and move the csv files to the final destination\n",
    "def unzip_stuff(starting_folder, final_destination, original_path=None):\n",
    "    #storing the original path because after the first iteration, the starting folder will change\n",
    "    if original_path is None:\n",
    "        original_path = starting_folder\n",
    "    print('Starting Folder:', starting_folder)\n",
    "    print('Final Destination:', final_destination)\n",
    "    files = os.listdir(starting_folder)\n",
    "\n",
    "    print('Beginning File Loop')\n",
    "    for file in files:\n",
    "        \n",
    "      \n",
    "        full_path = os.path.join(starting_folder, file)\n",
    "        print('File:', file)\n",
    "\n",
    "       \n",
    "        if file.endswith('.zip') and not re.search('citibike', file) is None :\n",
    "            print('Extracting:', file)\n",
    "            #unzip the file\n",
    "            try: \n",
    "                extract_path = os.path.join(starting_folder, file)\n",
    "                zipfile.ZipFile(extract_path).extractall(final_destination)\n",
    "\n",
    "                print('Removing:', file)\n",
    "                os.remove(extract_path) #remove the zip file after extracting\n",
    "                \n",
    "            except zipfile.BadZipFile:\n",
    "                print('Bad Zip File:', file)\n",
    "                continue\n",
    "\n",
    "            \n",
    "        elif file.endswith('.csv') and not re.search('citibike', file) is None:\n",
    "            print('Moving:', file)\n",
    "            \n",
    "            #move the csv file to the final destination\n",
    "            if not os.path.exists(os.path.join(final_destination, file)):\n",
    "                shutil.move(full_path, os.path.join(final_destination, file))\n",
    "            \n",
    "        elif os.path.isdir(full_path):\n",
    "            print('Moving into Folder:', file)\n",
    "            #else the file is alreays unzipped in a folder \n",
    "            unzip_stuff(full_path, final_destination)\n",
    "            \n",
    "        #made it all the way to the end of the loop    \n",
    "        os.chdir(original_path)\n",
    "\n",
    "unzip_stuff(starting_folder, final_destination)\n",
    "\n",
    "#check to see if the files were extracted\n",
    "os.chdir(final_destination)\n",
    "os.listdir('.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ba6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(final_destination) # we are in the data folder \n",
    "\n",
    "#lets remove the folders so that its doesnt mess us up\n",
    "for file in os.listdir('.'):\n",
    "    if os.path.isdir(file):\n",
    "        shutil.rmtree(file) #remove the folders\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a69db2",
   "metadata": {},
   "source": [
    "## File management complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd655c",
   "metadata": {},
   "source": [
    "## Appending the files and Fixing Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c221c",
   "metadata": {},
   "source": [
    "We have to fix the column names while we are appending bacaused we would be left with a bunch of random null values.\n",
    "It'll be easier to be proactive about it instead of trying to reconcile it afterwards. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0bac58",
   "metadata": {},
   "source": [
    "## Need to start with some testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d912e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count    Dtype  \n",
      "---  ------                   --------------    -----  \n",
      " 0   tripduration             1000000 non-null  int64  \n",
      " 1   starttime                1000000 non-null  object \n",
      " 2   stoptime                 1000000 non-null  object \n",
      " 3   start station id         1000000 non-null  int64  \n",
      " 4   start station name       1000000 non-null  object \n",
      " 5   start station latitude   1000000 non-null  float64\n",
      " 6   start station longitude  1000000 non-null  float64\n",
      " 7   end station id           1000000 non-null  int64  \n",
      " 8   end station name         1000000 non-null  object \n",
      " 9   end station latitude     1000000 non-null  float64\n",
      " 10  end station longitude    1000000 non-null  float64\n",
      " 11  bikeid                   1000000 non-null  int64  \n",
      " 12  usertype                 1000000 non-null  object \n",
      " 13  birth year               884506 non-null   float64\n",
      " 14  gender                   1000000 non-null  int64  \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 114.4+ MB\n",
      "None\n",
      "       tripduration  start station id  start station latitude  \\\n",
      "count  1.000000e+06    1000000.000000          1000000.000000   \n",
      "mean   1.039057e+03       1346.230151               40.736034   \n",
      "std    1.439600e+04       1340.826692                0.028249   \n",
      "min    6.100000e+01         72.000000               40.646538   \n",
      "25%    3.900000e+02        358.000000               40.717548   \n",
      "50%    6.590000e+02        485.000000               40.736529   \n",
      "75%    1.143000e+03       3140.000000               40.755273   \n",
      "max    4.182314e+06       3469.000000               40.880921   \n",
      "\n",
      "       start station longitude  end station id  end station latitude  \\\n",
      "count           1000000.000000  1000000.000000        1000000.000000   \n",
      "mean                -73.985123     1342.828010             40.735741   \n",
      "std                   0.017170     1340.264581              0.028173   \n",
      "min                 -74.017134       72.000000             40.646538   \n",
      "25%                 -73.997236      358.000000             40.717548   \n",
      "50%                 -73.987658      484.000000             40.736502   \n",
      "75%                 -73.976056     3140.000000             40.755103   \n",
      "max                 -73.896602     3469.000000             40.880921   \n",
      "\n",
      "       end station longitude          bikeid     birth year          gender  \n",
      "count         1000000.000000  1000000.000000  884506.000000  1000000.000000  \n",
      "mean              -73.985274    23040.331821    1978.814203        1.113142  \n",
      "std                 0.017189     4888.626888      11.643621        0.581626  \n",
      "min               -74.047727    14529.000000    1885.000000        0.000000  \n",
      "25%               -73.997249    18364.000000    1971.000000        1.000000  \n",
      "50%               -73.987763    25122.000000    1982.000000        1.000000  \n",
      "75%               -73.976206    27563.000000    1988.000000        1.000000  \n",
      "max               -73.896602    29823.000000    2001.000000        2.000000  \n",
      "   tripduration            starttime             stoptime  start station id  \\\n",
      "0          1397  2017-06-01 00:00:02  2017-06-01 00:23:19               515   \n",
      "1          1103  2017-06-01 00:00:13  2017-06-01 00:18:37               488   \n",
      "2          1810  2017-06-01 00:00:20  2017-06-01 00:30:31               461   \n",
      "3          1760  2017-06-01 00:00:24  2017-06-01 00:29:45              2009   \n",
      "4          2165  2017-06-01 00:00:33  2017-06-01 00:36:38               360   \n",
      "\n",
      "         start station name  start station latitude  start station longitude  \\\n",
      "0          W 43 St & 10 Ave               40.760094               -73.994618   \n",
      "1           W 39 St & 9 Ave               40.756458               -73.993722   \n",
      "2           E 20 St & 2 Ave               40.735877               -73.982050   \n",
      "3  Catherine St & Monroe St               40.711174               -73.996826   \n",
      "4      William St & Pine St               40.707179               -74.008873   \n",
      "\n",
      "   end station id          end station name  end station latitude  \\\n",
      "0            3285  W 87 St  & Amsterdam Ave             40.788390   \n",
      "1             297           E 15 St & 3 Ave             40.734232   \n",
      "2             465        Broadway & W 41 St             40.755136   \n",
      "3             527           E 33 St & 2 Ave             40.744023   \n",
      "4             474           5 Ave & E 29 St             40.745168   \n",
      "\n",
      "   end station longitude  bikeid    usertype  birth year  gender  \n",
      "0             -73.974700   26642  Subscriber      1967.0       1  \n",
      "1             -73.986923   25656  Subscriber      1981.0       1  \n",
      "2             -73.986580   21023  Subscriber      1982.0       1  \n",
      "3             -73.976056   25718  Subscriber      1973.0       2  \n",
      "4             -73.986831   18691  Subscriber      1985.0       1  \n"
     ]
    }
   ],
   "source": [
    "#list the files again to practice loading in a csv file and looking at the data\n",
    "import pandas as pd\n",
    "\n",
    "#it doesnt matter which file we open, lets start with the first one \n",
    "test_file = os.listdir('.')[0] \n",
    "\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "print(test_df.info())\n",
    "print(test_df.describe())\n",
    "print(test_df.head())\n",
    "\n",
    "#cool, im going to move on to appending that data together. I will do the data cleaning later after all of the files are appened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "678275f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 291\n",
      "Master Dataframe has 1000000 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/4mjb49y145s6l4jx6ds13c0r0000gn/T/ipykernel_8445/1321139162.py:29: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(all_files[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 has 1000000 rows.\n",
      "Master Dataframe updated to 2000000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/4mjb49y145s6l4jx6ds13c0r0000gn/T/ipykernel_8445/1321139162.py:29: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(all_files[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2 has 1000000 rows.\n",
      "Master Dataframe updated to 3000000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/4mjb49y145s6l4jx6ds13c0r0000gn/T/ipykernel_8445/1321139162.py:29: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(all_files[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 3 has 1000000 rows.\n",
      "Master Dataframe updated to 4000000 rows\n",
      "File 4 has 1000000 rows.\n",
      "Master Dataframe updated to 5000000 rows\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000000 entries, 0 to 4999999\n",
      "Data columns (total 28 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   tripduration             float64\n",
      " 1   starttime                object \n",
      " 2   stoptime                 object \n",
      " 3   start station id         float64\n",
      " 4   start station name       object \n",
      " 5   start station latitude   float64\n",
      " 6   start station longitude  float64\n",
      " 7   end station id           float64\n",
      " 8   end station name         object \n",
      " 9   end station latitude     float64\n",
      " 10  end station longitude    float64\n",
      " 11  bikeid                   float64\n",
      " 12  usertype                 object \n",
      " 13  birth year               float64\n",
      " 14  gender                   float64\n",
      " 15  ride_id                  object \n",
      " 16  rideable_type            object \n",
      " 17  started_at               object \n",
      " 18  ended_at                 object \n",
      " 19  start_station_name       object \n",
      " 20  start_station_id         object \n",
      " 21  end_station_name         object \n",
      " 22  end_station_id           object \n",
      " 23  start_lat                float64\n",
      " 24  start_lng                float64\n",
      " 25  end_lat                  float64\n",
      " 26  end_lng                  float64\n",
      " 27  member_casual            object \n",
      "dtypes: float64(14), object(14)\n",
      "memory usage: 1.0+ GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>1.999984e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>1.999984e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>1.884506e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>2.999130e+06</td>\n",
       "      <td>2.999130e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.068729e+03</td>\n",
       "      <td>1.506443e+03</td>\n",
       "      <td>4.073655e+01</td>\n",
       "      <td>-7.398355e+01</td>\n",
       "      <td>1.502682e+03</td>\n",
       "      <td>4.073624e+01</td>\n",
       "      <td>-7.398370e+01</td>\n",
       "      <td>2.618657e+04</td>\n",
       "      <td>1.979890e+03</td>\n",
       "      <td>1.133366e+00</td>\n",
       "      <td>4.074021e+01</td>\n",
       "      <td>-7.397513e+01</td>\n",
       "      <td>4.074019e+01</td>\n",
       "      <td>-7.397547e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.449420e+04</td>\n",
       "      <td>1.420294e+03</td>\n",
       "      <td>2.941209e-02</td>\n",
       "      <td>1.891359e-02</td>\n",
       "      <td>1.420278e+03</td>\n",
       "      <td>2.934540e-02</td>\n",
       "      <td>1.897092e-02</td>\n",
       "      <td>7.118145e+03</td>\n",
       "      <td>1.185767e+01</td>\n",
       "      <td>5.763558e-01</td>\n",
       "      <td>3.917983e-02</td>\n",
       "      <td>2.657652e-02</td>\n",
       "      <td>4.570636e-02</td>\n",
       "      <td>5.036013e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.100000e+01</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>4.064654e+01</td>\n",
       "      <td>-7.402535e+01</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>4.064654e+01</td>\n",
       "      <td>-7.406860e+01</td>\n",
       "      <td>1.452900e+04</td>\n",
       "      <td>1.885000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.059937e+01</td>\n",
       "      <td>-7.403878e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.421000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.910000e+02</td>\n",
       "      <td>3.680000e+02</td>\n",
       "      <td>4.071749e+01</td>\n",
       "      <td>-7.399667e+01</td>\n",
       "      <td>3.660000e+02</td>\n",
       "      <td>4.071745e+01</td>\n",
       "      <td>-7.399705e+01</td>\n",
       "      <td>1.953900e+04</td>\n",
       "      <td>1.970000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.071541e+01</td>\n",
       "      <td>-7.399393e+01</td>\n",
       "      <td>4.071534e+01</td>\n",
       "      <td>-7.399405e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.690000e+02</td>\n",
       "      <td>4.970000e+02</td>\n",
       "      <td>4.073705e+01</td>\n",
       "      <td>-7.398683e+01</td>\n",
       "      <td>4.970000e+02</td>\n",
       "      <td>4.073650e+01</td>\n",
       "      <td>-7.398692e+01</td>\n",
       "      <td>2.684600e+04</td>\n",
       "      <td>1.983000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.073945e+01</td>\n",
       "      <td>-7.398142e+01</td>\n",
       "      <td>4.073989e+01</td>\n",
       "      <td>-7.398192e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.171000e+03</td>\n",
       "      <td>3.173000e+03</td>\n",
       "      <td>4.075646e+01</td>\n",
       "      <td>-7.397371e+01</td>\n",
       "      <td>3.175000e+03</td>\n",
       "      <td>4.075601e+01</td>\n",
       "      <td>-7.397375e+01</td>\n",
       "      <td>3.059400e+04</td>\n",
       "      <td>1.989000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.076323e+01</td>\n",
       "      <td>-7.395927e+01</td>\n",
       "      <td>4.076360e+01</td>\n",
       "      <td>-7.395962e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.182314e+06</td>\n",
       "      <td>3.804000e+03</td>\n",
       "      <td>4.088092e+01</td>\n",
       "      <td>-7.388400e+01</td>\n",
       "      <td>3.804000e+03</td>\n",
       "      <td>4.088092e+01</td>\n",
       "      <td>-7.388700e+01</td>\n",
       "      <td>4.002500e+04</td>\n",
       "      <td>2.003000e+03</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.089000e+01</td>\n",
       "      <td>-7.384670e+01</td>\n",
       "      <td>4.094000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tripduration  start station id  start station latitude  \\\n",
       "count  2.000000e+06      1.999984e+06            2.000000e+06   \n",
       "mean   1.068729e+03      1.506443e+03            4.073655e+01   \n",
       "std    1.449420e+04      1.420294e+03            2.941209e-02   \n",
       "min    6.100000e+01      7.200000e+01            4.064654e+01   \n",
       "25%    3.910000e+02      3.680000e+02            4.071749e+01   \n",
       "50%    6.690000e+02      4.970000e+02            4.073705e+01   \n",
       "75%    1.171000e+03      3.173000e+03            4.075646e+01   \n",
       "max    4.182314e+06      3.804000e+03            4.088092e+01   \n",
       "\n",
       "       start station longitude  end station id  end station latitude  \\\n",
       "count             2.000000e+06    1.999984e+06          2.000000e+06   \n",
       "mean             -7.398355e+01    1.502682e+03          4.073624e+01   \n",
       "std               1.891359e-02    1.420278e+03          2.934540e-02   \n",
       "min              -7.402535e+01    7.200000e+01          4.064654e+01   \n",
       "25%              -7.399667e+01    3.660000e+02          4.071745e+01   \n",
       "50%              -7.398683e+01    4.970000e+02          4.073650e+01   \n",
       "75%              -7.397371e+01    3.175000e+03          4.075601e+01   \n",
       "max              -7.388400e+01    3.804000e+03          4.088092e+01   \n",
       "\n",
       "       end station longitude        bikeid    birth year        gender  \\\n",
       "count           2.000000e+06  2.000000e+06  1.884506e+06  2.000000e+06   \n",
       "mean           -7.398370e+01  2.618657e+04  1.979890e+03  1.133366e+00   \n",
       "std             1.897092e-02  7.118145e+03  1.185767e+01  5.763558e-01   \n",
       "min            -7.406860e+01  1.452900e+04  1.885000e+03  0.000000e+00   \n",
       "25%            -7.399705e+01  1.953900e+04  1.970000e+03  1.000000e+00   \n",
       "50%            -7.398692e+01  2.684600e+04  1.983000e+03  1.000000e+00   \n",
       "75%            -7.397375e+01  3.059400e+04  1.989000e+03  1.000000e+00   \n",
       "max            -7.388700e+01  4.002500e+04  2.003000e+03  2.000000e+00   \n",
       "\n",
       "          start_lat     start_lng       end_lat       end_lng  \n",
       "count  3.000000e+06  3.000000e+06  2.999130e+06  2.999130e+06  \n",
       "mean   4.074021e+01 -7.397513e+01  4.074019e+01 -7.397547e+01  \n",
       "std    3.917983e-02  2.657652e-02  4.570636e-02  5.036013e-02  \n",
       "min    4.059937e+01 -7.403878e+01  0.000000e+00 -7.421000e+01  \n",
       "25%    4.071541e+01 -7.399393e+01  4.071534e+01 -7.399405e+01  \n",
       "50%    4.073945e+01 -7.398142e+01  4.073989e+01 -7.398192e+01  \n",
       "75%    4.076323e+01 -7.395927e+01  4.076360e+01 -7.395962e+01  \n",
       "max    4.089000e+01 -7.384670e+01  4.094000e+01  0.000000e+00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I've never done this before in python so I dont know if the most efficient way is to do this in a loop or not. I think it will be easier to do it in a loop so that I can see the progress.\n",
    "# I will also add a progress bar to see how long it takes to run.\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "#lets me do an optional argumen tin the append fuction: \n",
    "from typing import Optional, Tuple\n",
    "\n",
    "#lets make a list of all the csv files in the data folder\n",
    "os.chdir(final_destination)\n",
    "all_files = glob.glob('*.csv')\n",
    "print('Number of files:', len(all_files))\n",
    "\n",
    "#I dont care about the names of the files, I just want to append them together\n",
    "#you may ask does the file include the date? yes, in the start time and end time columns, so we can ignore file names. \n",
    "# i first have to make it a data frame and append to the \"master data frame\"\n",
    "#testing with the first 5 files\n",
    "def append_my_files(all_files, testing: Optional[tuple[int, int]] = None):\n",
    "    if testing is not None: \n",
    "        #testing sould be an a tupple specifying start and stop \n",
    "        start = testing[0]\n",
    "        stop = testing[1]\n",
    "        all_files = all_files[start:stop]\n",
    "\n",
    "    for i in range(len(all_files[:5])):\n",
    "        if i == 0: \n",
    "            master_df = pd.read_csv(all_files[i])\n",
    "            print(f'Master Dataframe has {len(master_df)} rows.')\n",
    "        else:\n",
    "            temp_df = pd.read_csv(all_files[i])\n",
    "            print(f'File {i} has {len(temp_df)} rows.')\n",
    "\n",
    "            try: \n",
    "                master_df = pd.concat([master_df, temp_df], ignore_index=True, sort=False)\n",
    "                print(f'Master Dataframe updated to {len(master_df)} rows')\n",
    "                #lets de dupe before the file gets too big <3\n",
    "                master_df = master_df.drop_duplicates()\n",
    "                del temp_df\n",
    "            except: \n",
    "                raise AttributeError(\"Something went wrong!!\")\n",
    "    return master_df\n",
    "\n",
    "master_df = append_my_files(all_files, (0,5))\n",
    "\n",
    "master_df.info()\n",
    "master_df.describe()\n",
    "#i see we already have an issue with naming conventions - we need to remedy the column names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c806b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/4mjb49y145s6l4jx6ds13c0r0000gn/T/ipykernel_8445/1321139162.py:26: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  master_df = pd.read_csv(all_files[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Dataframe has 1000000 rows.\n",
      "File 1 has 573872 rows.\n",
      "Master Dataframe updated to 1573872 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>...</th>\n",
       "      <th>Start Station Latitude</th>\n",
       "      <th>Start Station Longitude</th>\n",
       "      <th>End Station ID</th>\n",
       "      <th>End Station Name</th>\n",
       "      <th>End Station Latitude</th>\n",
       "      <th>End Station Longitude</th>\n",
       "      <th>Bike ID</th>\n",
       "      <th>User Type</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211D9837F472C1C2</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-07-06 18:11:50.566</td>\n",
       "      <td>2022-07-06 18:18:34.784</td>\n",
       "      <td>6 Ave &amp; Canal St</td>\n",
       "      <td>5500.07</td>\n",
       "      <td>Washington St &amp; Barrow St</td>\n",
       "      <td>5847.08</td>\n",
       "      <td>40.722438</td>\n",
       "      <td>-74.005664</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4FFB0D6FD9D92275</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-07-03 23:02:50.580</td>\n",
       "      <td>2022-07-03 23:31:47.420</td>\n",
       "      <td>Van Buren St &amp; Broadway</td>\n",
       "      <td>4568.01</td>\n",
       "      <td>Frost St &amp; Meeker Ave</td>\n",
       "      <td>5371.07</td>\n",
       "      <td>40.692000</td>\n",
       "      <td>-73.926170</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66002E6013735A7A</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-07-12 21:38:22.305</td>\n",
       "      <td>2022-07-12 21:43:00.280</td>\n",
       "      <td>E 2 St &amp; 2 Ave</td>\n",
       "      <td>5593.02</td>\n",
       "      <td>E 2 St &amp; Avenue C</td>\n",
       "      <td>5476.03</td>\n",
       "      <td>40.725029</td>\n",
       "      <td>-73.990697</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693D5CC23DB43405</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-07-26 14:01:02.148</td>\n",
       "      <td>2022-07-26 14:19:59.416</td>\n",
       "      <td>Central Park North &amp; Adam Clayton Powell Blvd</td>\n",
       "      <td>7617.07</td>\n",
       "      <td>Central Park North &amp; Adam Clayton Powell Blvd</td>\n",
       "      <td>7617.07</td>\n",
       "      <td>40.799484</td>\n",
       "      <td>-73.955613</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D25A8F6EEBA4D0D4</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-07-17 11:11:32.390</td>\n",
       "      <td>2022-07-17 11:18:14.532</td>\n",
       "      <td>Broadway &amp; E 19 St</td>\n",
       "      <td>6098.12</td>\n",
       "      <td>W 20 St &amp; 10 Ave</td>\n",
       "      <td>6306.01</td>\n",
       "      <td>40.738661</td>\n",
       "      <td>-73.989873</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573867</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.732264</td>\n",
       "      <td>-73.998522</td>\n",
       "      <td>311.0</td>\n",
       "      <td>Norfolk St &amp; Broome St</td>\n",
       "      <td>40.717227</td>\n",
       "      <td>-73.988021</td>\n",
       "      <td>15261.0</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573868</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.722055</td>\n",
       "      <td>-73.989111</td>\n",
       "      <td>268.0</td>\n",
       "      <td>Howard St &amp; Centre St</td>\n",
       "      <td>40.719105</td>\n",
       "      <td>-73.999733</td>\n",
       "      <td>26471.0</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.764210</td>\n",
       "      <td>-73.969105</td>\n",
       "      <td>3226.0</td>\n",
       "      <td>W 82 St &amp; Central Park West</td>\n",
       "      <td>40.782750</td>\n",
       "      <td>-73.971370</td>\n",
       "      <td>24033.0</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573870</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.701485</td>\n",
       "      <td>-73.986569</td>\n",
       "      <td>274.0</td>\n",
       "      <td>Lafayette Ave &amp; Fort Greene Pl</td>\n",
       "      <td>40.686919</td>\n",
       "      <td>-73.976682</td>\n",
       "      <td>25841.0</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573871</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.719261</td>\n",
       "      <td>-73.981780</td>\n",
       "      <td>473.0</td>\n",
       "      <td>Rivington St &amp; Chrystie St</td>\n",
       "      <td>40.721101</td>\n",
       "      <td>-73.991925</td>\n",
       "      <td>24820.0</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573872 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ride_id  rideable_type               started_at  \\\n",
       "0        211D9837F472C1C2   classic_bike  2022-07-06 18:11:50.566   \n",
       "1        4FFB0D6FD9D92275  electric_bike  2022-07-03 23:02:50.580   \n",
       "2        66002E6013735A7A   classic_bike  2022-07-12 21:38:22.305   \n",
       "3        693D5CC23DB43405   classic_bike  2022-07-26 14:01:02.148   \n",
       "4        D25A8F6EEBA4D0D4   classic_bike  2022-07-17 11:11:32.390   \n",
       "...                   ...            ...                      ...   \n",
       "1573867               NaN            NaN                      NaN   \n",
       "1573868               NaN            NaN                      NaN   \n",
       "1573869               NaN            NaN                      NaN   \n",
       "1573870               NaN            NaN                      NaN   \n",
       "1573871               NaN            NaN                      NaN   \n",
       "\n",
       "                        ended_at  \\\n",
       "0        2022-07-06 18:18:34.784   \n",
       "1        2022-07-03 23:31:47.420   \n",
       "2        2022-07-12 21:43:00.280   \n",
       "3        2022-07-26 14:19:59.416   \n",
       "4        2022-07-17 11:18:14.532   \n",
       "...                          ...   \n",
       "1573867                      NaN   \n",
       "1573868                      NaN   \n",
       "1573869                      NaN   \n",
       "1573870                      NaN   \n",
       "1573871                      NaN   \n",
       "\n",
       "                                    start_station_name start_station_id  \\\n",
       "0                                     6 Ave & Canal St          5500.07   \n",
       "1                              Van Buren St & Broadway          4568.01   \n",
       "2                                       E 2 St & 2 Ave          5593.02   \n",
       "3        Central Park North & Adam Clayton Powell Blvd          7617.07   \n",
       "4                                   Broadway & E 19 St          6098.12   \n",
       "...                                                ...              ...   \n",
       "1573867                                            NaN              NaN   \n",
       "1573868                                            NaN              NaN   \n",
       "1573869                                            NaN              NaN   \n",
       "1573870                                            NaN              NaN   \n",
       "1573871                                            NaN              NaN   \n",
       "\n",
       "                                      end_station_name end_station_id  \\\n",
       "0                            Washington St & Barrow St        5847.08   \n",
       "1                                Frost St & Meeker Ave        5371.07   \n",
       "2                                    E 2 St & Avenue C        5476.03   \n",
       "3        Central Park North & Adam Clayton Powell Blvd        7617.07   \n",
       "4                                     W 20 St & 10 Ave        6306.01   \n",
       "...                                                ...            ...   \n",
       "1573867                                            NaN            NaN   \n",
       "1573868                                            NaN            NaN   \n",
       "1573869                                            NaN            NaN   \n",
       "1573870                                            NaN            NaN   \n",
       "1573871                                            NaN            NaN   \n",
       "\n",
       "         start_lat  start_lng  ...  Start Station Latitude  \\\n",
       "0        40.722438 -74.005664  ...                     NaN   \n",
       "1        40.692000 -73.926170  ...                     NaN   \n",
       "2        40.725029 -73.990697  ...                     NaN   \n",
       "3        40.799484 -73.955613  ...                     NaN   \n",
       "4        40.738661 -73.989873  ...                     NaN   \n",
       "...            ...        ...  ...                     ...   \n",
       "1573867        NaN        NaN  ...               40.732264   \n",
       "1573868        NaN        NaN  ...               40.722055   \n",
       "1573869        NaN        NaN  ...               40.764210   \n",
       "1573870        NaN        NaN  ...               40.701485   \n",
       "1573871        NaN        NaN  ...               40.719261   \n",
       "\n",
       "         Start Station Longitude End Station ID  \\\n",
       "0                            NaN            NaN   \n",
       "1                            NaN            NaN   \n",
       "2                            NaN            NaN   \n",
       "3                            NaN            NaN   \n",
       "4                            NaN            NaN   \n",
       "...                          ...            ...   \n",
       "1573867               -73.998522          311.0   \n",
       "1573868               -73.989111          268.0   \n",
       "1573869               -73.969105         3226.0   \n",
       "1573870               -73.986569          274.0   \n",
       "1573871               -73.981780          473.0   \n",
       "\n",
       "                       End Station Name End Station Latitude  \\\n",
       "0                                   NaN                  NaN   \n",
       "1                                   NaN                  NaN   \n",
       "2                                   NaN                  NaN   \n",
       "3                                   NaN                  NaN   \n",
       "4                                   NaN                  NaN   \n",
       "...                                 ...                  ...   \n",
       "1573867          Norfolk St & Broome St            40.717227   \n",
       "1573868           Howard St & Centre St            40.719105   \n",
       "1573869     W 82 St & Central Park West            40.782750   \n",
       "1573870  Lafayette Ave & Fort Greene Pl            40.686919   \n",
       "1573871      Rivington St & Chrystie St            40.721101   \n",
       "\n",
       "        End Station Longitude  Bike ID   User Type  Birth Year  Gender  \n",
       "0                         NaN      NaN         NaN         NaN     NaN  \n",
       "1                         NaN      NaN         NaN         NaN     NaN  \n",
       "2                         NaN      NaN         NaN         NaN     NaN  \n",
       "3                         NaN      NaN         NaN         NaN     NaN  \n",
       "4                         NaN      NaN         NaN         NaN     NaN  \n",
       "...                       ...      ...         ...         ...     ...  \n",
       "1573867            -73.988021  15261.0  Subscriber      1983.0     2.0  \n",
       "1573868            -73.999733  26471.0  Subscriber      1989.0     1.0  \n",
       "1573869            -73.971370  24033.0  Subscriber      1983.0     1.0  \n",
       "1573870            -73.976682  25841.0  Subscriber      1974.0     1.0  \n",
       "1573871            -73.991925  24820.0  Subscriber      1990.0     2.0  \n",
       "\n",
       "[1573872 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying a different set of files \n",
    "append_my_files(all_files, (30, 32))\n",
    "#aha i finall see in intersection where nulls meet!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62dd4814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/4mjb49y145s6l4jx6ds13c0r0000gn/T/ipykernel_8445/3178750555.py:4: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file_1 = pd.read_csv(all_files[30])\n"
     ]
    }
   ],
   "source": [
    "#So we need to fix column names while we append the files. \n",
    "#some options: a dictionary to rename columns, if the files have the same order of variables then we can just rename columns instead of using header \n",
    "#lets load two files in different data frames to compare -- after appending everything gets out of order based on the original file \n",
    "file_1 = pd.read_csv(all_files[30])\n",
    "file_2 = pd.read_csv(all_files[31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a127beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   ride_id             1000000 non-null  object \n",
      " 1   rideable_type       1000000 non-null  object \n",
      " 2   started_at          1000000 non-null  object \n",
      " 3   ended_at            1000000 non-null  object \n",
      " 4   start_station_name  1000000 non-null  object \n",
      " 5   start_station_id    1000000 non-null  object \n",
      " 6   end_station_name    996332 non-null   object \n",
      " 7   end_station_id      996332 non-null   object \n",
      " 8   start_lat           1000000 non-null  float64\n",
      " 9   start_lng           1000000 non-null  float64\n",
      " 10  end_lat             998292 non-null   float64\n",
      " 11  end_lng             998292 non-null   float64\n",
      " 12  member_casual       1000000 non-null  object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 99.2+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_1.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6063478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 573872 entries, 0 to 573871\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   Trip Duration            573872 non-null  int64  \n",
      " 1   Start Time               573872 non-null  object \n",
      " 2   Stop Time                573872 non-null  object \n",
      " 3   Start Station ID         573872 non-null  int64  \n",
      " 4   Start Station Name       573872 non-null  object \n",
      " 5   Start Station Latitude   573872 non-null  float64\n",
      " 6   Start Station Longitude  573872 non-null  float64\n",
      " 7   End Station ID           573872 non-null  int64  \n",
      " 8   End Station Name         573872 non-null  object \n",
      " 9   End Station Latitude     573872 non-null  float64\n",
      " 10  End Station Longitude    573872 non-null  float64\n",
      " 11  Bike ID                  573872 non-null  int64  \n",
      " 12  User Type                567944 non-null  object \n",
      " 13  Birth Year               518300 non-null  float64\n",
      " 14  Gender                   573872 non-null  int64  \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 65.7+ MB\n"
     ]
    }
   ],
   "source": [
    "file_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233ddce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Type\n",
      "Subscriber    517425\n",
      "Customer       50519\n",
      "Name: count, dtype: int64\n",
      "member_casual\n",
      "member    760241\n",
      "casual    239759\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# we can make this work we'll just need to clean it \n",
    "print(file_2['User Type'].value_counts())\n",
    "print(file_1['member_casual'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02c9a847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip Duration ('end_station_id', 49)\n",
      "Start Time ('start_station_name', 64)\n",
      "Stop Time ('end_station_name', 48)\n",
      "Start Station ID ('start_station_id', 88)\n",
      "Start Station Name ('start_station_name', 89)\n",
      "Start Station Latitude ('start_station_id', 74)\n",
      "Start Station Longitude ('start_station_id', 72)\n",
      "End Station ID ('end_station_id', 86)\n",
      "End Station Name ('end_station_name', 88)\n",
      "End Station Latitude ('end_lat', 74)\n",
      "End Station Longitude ('end_station_id', 69)\n",
      "Bike ID ('start_station_id', 39)\n",
      "User Type ('rideable_type', 45)\n",
      "Birth Year ('started_at', 40)\n",
      "Gender ('ended_at', 57)\n",
      "{'start_time': 'started_at', 'stop_time': 'ended_at', 'starttime': 'started_at', 'stoptime': 'ended_at', 'start_station_id': 'start_station_id', 'start_station_name': 'start_station_name', 'end_station_id': 'end_station_id', 'end_station_name': 'end_station_name', 'start_station_latitude': 'start_lat', 'start_station_longitude': 'start_lng', 'end_station_latitude': 'end_lat', 'end_station_longitude': 'end_lng', 'user_type': 'member_casual', 'usertype': 'member_casual'}\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 573872 entries, 0 to 573871\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   trip_duration       573872 non-null  int64  \n",
      " 1   started_at          573872 non-null  object \n",
      " 2   ended_at            573872 non-null  object \n",
      " 3   start_station_id    573872 non-null  int64  \n",
      " 4   start_station_name  573872 non-null  object \n",
      " 5   start_lat           573872 non-null  float64\n",
      " 6   start_lng           573872 non-null  float64\n",
      " 7   end_station_id      573872 non-null  int64  \n",
      " 8   end_station_name    573872 non-null  object \n",
      " 9   end_lat             573872 non-null  float64\n",
      " 10  end_lng             573872 non-null  float64\n",
      " 11  bike_id             573872 non-null  int64  \n",
      " 12  member_casual       567944 non-null  object \n",
      " 13  birth_year          518300 non-null  float64\n",
      " 14  gender              573872 non-null  int64  \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 65.7+ MB\n",
      "['started_at', 'ended_at', 'started_at', 'ended_at', 'start_station_id', 'start_station_name', 'end_station_id', 'end_station_name', 'start_lat', 'start_lng', 'end_lat', 'end_lng', 'member_casual', 'member_casual']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccahess/anaconda3/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "#They are not in order so we'll have to make a translation -- there are also more variables in some files than others \n",
    "#for viewing purposes \n",
    "#lets make a translation table -- google recommends making a dictionary and doing a mapping.\n",
    "# I prefer the names to have the underscores so I am starting with file 2. \n",
    "# further im going to use fuzzywuzzy matching because why not -- its cute. \n",
    "\n",
    "#I believe process will do the dirty work for me \n",
    "from fuzzywuzzy import process \n",
    "for col in file_2.columns:\n",
    "    print(col, process.extractOne(col, file_1.columns))\n",
    "\n",
    "#scratching thisp; the columns are not enough alike \n",
    "#just going to make an empty dictionary then replact the ones I know to be true. Im not messing with getting them mistranslated.\n",
    "col_translation = {}\n",
    "col_translation['Start Time'] = 'started_at'\n",
    "col_translation['Stop Time'] = 'ended_at'\n",
    "col_translation['StartTime'] = 'started_at'\n",
    "col_translation['StopTime'] = 'ended_at'\n",
    "col_translation['Start Station ID'] = 'start_station_id'\n",
    "col_translation['Start Station Name'] = 'start_station_name'\n",
    "col_translation['End Station ID'] = 'end_station_id'\n",
    "col_translation['End Station Name'] = 'end_station_name'\n",
    "col_translation['Start Station Latitude'] = 'start_lat'\n",
    "col_translation['Start Station Longitude'] = 'start_lng'\n",
    "col_translation['End Station Latitude'] = 'end_lat'\n",
    "col_translation['End Station Longitude'] = 'end_lng'\n",
    "col_translation['User Type']='member_casual'\n",
    "col_translation['UserType']='member_casual'\n",
    "#making this lower after the fact \n",
    "col_translation = {k.lower():v for k,v in col_translation.items()}\n",
    "#replacing spaces with underscored for readability \n",
    "col_translation = {k.replace(' ', '_'):v for k,v in col_translation.items()}\n",
    "print(col_translation)\n",
    " \n",
    "#testing on our files \n",
    "file_2.columns = file_2.columns.str.lower()\n",
    "file_2.columns = file_2.columns.str.replace(' ', '_')\n",
    "file_2_renamed = file_2.rename(columns=col_translation)\n",
    "#file_2.info()\n",
    "file_2_renamed.info()\n",
    "\n",
    "# we would need to drop the extraneous cols \n",
    "keep_cols = [v for k,v in col_translation.items()]\n",
    "print(keep_cols)\n",
    "file_2_renamed=file_2_renamed[keep_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48b150",
   "metadata": {},
   "source": [
    "## Done with Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d060ce",
   "metadata": {},
   "source": [
    "## Final program for appending the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#putting this all together, we need to update the append files program to do a bit of intermediate file cleaning\n",
    "#adding a second function to do that things we want\n",
    "def df_adjust(file, col_translation):\n",
    "    if col_translation is not None:\n",
    "            file.columns = file.columns.str.lower()\n",
    "             #replace any spaces with underscores \n",
    "            file.columns = file.columns.str.replace(' ', '_')\n",
    "            \n",
    "            #i need to adjust the col_translation depending on the starting variables so we don't accidentally get duplicates again\n",
    "            col_translation_updtd = {k:v for k,v in col_translation.items() if k in file.columns}\n",
    "            #testing on our files \n",
    "            file_renamed = file.rename(columns=col_translation_updtd)\n",
    "    else: \n",
    "        file_renamed = file \n",
    "\n",
    "    #added set function to address the duplicate problem \n",
    "    #there are m:1 relationships\n",
    "    keep_cols = [v for v in set(col_translation.values())]\n",
    "    try: \n",
    "        file_renamed = file_renamed[keep_cols]\n",
    "    except: \n",
    "        not_found = [col  for col in keep_cols if col not in file_renamed.columns]\n",
    "        joined_columns = '\\n    -'.join(not_found)\n",
    "        raise KeyError(f\"New columns not listed in col translation:\\n    -{joined_columns}\")\n",
    "    \n",
    "    file_trimmed= file_renamed.dropna(how = 'any') #reduce\n",
    "    file_sampled = file_trimmed.sample(frac=0.001) # they are ginormous, lets just keep .1% of the file \n",
    "    return file_sampled\n",
    "    \n",
    "        \n",
    "\n",
    "#copying the program here and making changes\n",
    "def append_my_files(all_files, testing: Optional[tuple[int, int]] = None, col_translation=None):\n",
    "    if testing is not None: \n",
    "        #testing sould be an a tuple specifying start and stop \n",
    "        start = testing[0]\n",
    "        stop = testing[1]\n",
    "        all_files = all_files[start:stop]\n",
    "\n",
    "    for i in range(len(all_files)):\n",
    "        if i == 0: \n",
    "            master_df = pd.read_csv(all_files[i], low_memory=False)\n",
    "            \n",
    "            master_df = df_adjust(master_df, col_translation) # renaming columns, dropping duplicates, removing na values, and sampling the data set \n",
    "\n",
    "            print(f'Master Dataframe has {len(master_df)} rows.')\n",
    "        else:\n",
    "            temp_df = pd.read_csv(all_files[i], low_memory=False)\n",
    "            temp_df = df_adjust(temp_df, col_translation) # renaming columns, dropping duplicates, removing na values, and sampling the data set \n",
    "            print(f'File {i} has {len(temp_df)} rows.')\n",
    "\n",
    "            try: \n",
    "                master_df = pd.concat([master_df, temp_df], ignore_index=True, sort=False)\n",
    "                print(f'Master Dataframe updated to {len(master_df)} rows')\n",
    "                #lets de dupe before the file gets too big <3\n",
    "                master_df = master_df.drop_duplicates()\n",
    "                del temp_df\n",
    "            except: \n",
    "                raise AttributeError(\"Something went wrong!!\")\n",
    "    #moving into the program because i am checking every time anyway \n",
    "    master_df.info()\n",
    "    master_df.describe()\n",
    "    master_df.head()\n",
    "    return master_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af4734f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Dataframe has 1000 rows.\n",
      "File 1 has 992 rows.\n",
      "Master Dataframe updated to 1992 rows\n",
      "File 2 has 1000 rows.\n",
      "Master Dataframe updated to 2992 rows\n",
      "File 3 has 1000 rows.\n",
      "Master Dataframe updated to 3992 rows\n",
      "File 4 has 1000 rows.\n",
      "Master Dataframe updated to 4992 rows\n",
      "File 5 has 1000 rows.\n",
      "Master Dataframe updated to 5992 rows\n",
      "File 6 has 991 rows.\n",
      "Master Dataframe updated to 6983 rows\n",
      "File 7 has 994 rows.\n",
      "Master Dataframe updated to 7977 rows\n",
      "File 8 has 1000 rows.\n",
      "Master Dataframe updated to 8977 rows\n",
      "File 9 has 988 rows.\n",
      "Master Dataframe updated to 9965 rows\n",
      "File 10 has 1000 rows.\n",
      "Master Dataframe updated to 10965 rows\n",
      "File 11 has 996 rows.\n",
      "Master Dataframe updated to 11961 rows\n",
      "File 12 has 1000 rows.\n",
      "Master Dataframe updated to 12961 rows\n",
      "File 13 has 1000 rows.\n",
      "Master Dataframe updated to 13961 rows\n",
      "File 14 has 205 rows.\n",
      "Master Dataframe updated to 14166 rows\n",
      "File 15 has 1000 rows.\n",
      "Master Dataframe updated to 15166 rows\n",
      "File 16 has 1877 rows.\n",
      "Master Dataframe updated to 17043 rows\n",
      "File 17 has 993 rows.\n",
      "Master Dataframe updated to 18036 rows\n",
      "File 18 has 1000 rows.\n",
      "Master Dataframe updated to 19036 rows\n",
      "File 19 has 986 rows.\n",
      "Master Dataframe updated to 20022 rows\n",
      "File 20 has 732 rows.\n",
      "Master Dataframe updated to 20754 rows\n",
      "File 21 has 3209 rows.\n",
      "Master Dataframe updated to 23963 rows\n",
      "File 22 has 998 rows.\n",
      "Master Dataframe updated to 24961 rows\n",
      "File 23 has 453 rows.\n",
      "Master Dataframe updated to 25414 rows\n",
      "File 24 has 719 rows.\n",
      "Master Dataframe updated to 26133 rows\n",
      "File 25 has 1000 rows.\n",
      "Master Dataframe updated to 27133 rows\n",
      "File 26 has 181 rows.\n",
      "Master Dataframe updated to 27314 rows\n",
      "File 27 has 920 rows.\n",
      "Master Dataframe updated to 28234 rows\n",
      "File 28 has 993 rows.\n",
      "Master Dataframe updated to 29227 rows\n",
      "File 29 has 723 rows.\n",
      "Master Dataframe updated to 29950 rows\n",
      "File 30 has 996 rows.\n",
      "Master Dataframe updated to 30946 rows\n",
      "File 31 has 568 rows.\n",
      "Master Dataframe updated to 31514 rows\n",
      "File 32 has 898 rows.\n",
      "Master Dataframe updated to 32412 rows\n",
      "File 33 has 999 rows.\n",
      "Master Dataframe updated to 33411 rows\n",
      "File 34 has 795 rows.\n",
      "Master Dataframe updated to 34206 rows\n",
      "File 35 has 17 rows.\n",
      "Master Dataframe updated to 34223 rows\n",
      "File 36 has 1000 rows.\n",
      "Master Dataframe updated to 35223 rows\n",
      "File 37 has 344 rows.\n",
      "Master Dataframe updated to 35567 rows\n",
      "File 38 has 719 rows.\n",
      "Master Dataframe updated to 36286 rows\n",
      "File 39 has 999 rows.\n",
      "Master Dataframe updated to 37284 rows\n",
      "File 40 has 998 rows.\n",
      "Master Dataframe updated to 38282 rows\n",
      "File 41 has 1000 rows.\n",
      "Master Dataframe updated to 39282 rows\n",
      "File 42 has 994 rows.\n",
      "Master Dataframe updated to 40276 rows\n",
      "File 43 has 558 rows.\n",
      "Master Dataframe updated to 40834 rows\n",
      "File 44 has 113 rows.\n",
      "Master Dataframe updated to 40947 rows\n",
      "File 45 has 93 rows.\n",
      "Master Dataframe updated to 41040 rows\n",
      "File 46 has 230 rows.\n",
      "Master Dataframe updated to 41270 rows\n",
      "File 47 has 992 rows.\n",
      "Master Dataframe updated to 42262 rows\n",
      "File 48 has 992 rows.\n",
      "Master Dataframe updated to 43254 rows\n",
      "File 49 has 683 rows.\n",
      "Master Dataframe updated to 43937 rows\n",
      "File 50 has 398 rows.\n",
      "Master Dataframe updated to 44335 rows\n",
      "File 51 has 576 rows.\n",
      "Master Dataframe updated to 44911 rows\n",
      "File 52 has 878 rows.\n",
      "Master Dataframe updated to 45789 rows\n",
      "File 53 has 995 rows.\n",
      "Master Dataframe updated to 46784 rows\n",
      "File 54 has 844 rows.\n",
      "Master Dataframe updated to 47628 rows\n",
      "File 55 has 1000 rows.\n",
      "Master Dataframe updated to 48628 rows\n",
      "File 56 has 220 rows.\n",
      "Master Dataframe updated to 48848 rows\n",
      "File 57 has 1000 rows.\n",
      "Master Dataframe updated to 49848 rows\n",
      "File 58 has 380 rows.\n",
      "Master Dataframe updated to 50228 rows\n",
      "File 59 has 825 rows.\n",
      "Master Dataframe updated to 51053 rows\n",
      "File 60 has 328 rows.\n",
      "Master Dataframe updated to 51381 rows\n",
      "File 61 has 1000 rows.\n",
      "Master Dataframe updated to 52381 rows\n",
      "File 62 has 1000 rows.\n",
      "Master Dataframe updated to 53381 rows\n",
      "File 63 has 977 rows.\n",
      "Master Dataframe updated to 54358 rows\n",
      "File 64 has 1000 rows.\n",
      "Master Dataframe updated to 55358 rows\n",
      "File 65 has 1000 rows.\n",
      "Master Dataframe updated to 56358 rows\n",
      "File 66 has 311 rows.\n",
      "Master Dataframe updated to 56669 rows\n",
      "File 67 has 635 rows.\n",
      "Master Dataframe updated to 57304 rows\n",
      "File 68 has 1000 rows.\n",
      "Master Dataframe updated to 58304 rows\n",
      "File 69 has 997 rows.\n",
      "Master Dataframe updated to 59301 rows\n",
      "File 70 has 114 rows.\n",
      "Master Dataframe updated to 59415 rows\n",
      "File 71 has 1000 rows.\n",
      "Master Dataframe updated to 60415 rows\n",
      "File 72 has 1000 rows.\n",
      "Master Dataframe updated to 61415 rows\n",
      "File 73 has 1000 rows.\n",
      "Master Dataframe updated to 62415 rows\n",
      "File 74 has 937 rows.\n",
      "Master Dataframe updated to 63352 rows\n",
      "File 75 has 1000 rows.\n",
      "Master Dataframe updated to 64352 rows\n",
      "File 76 has 1000 rows.\n",
      "Master Dataframe updated to 65352 rows\n",
      "File 77 has 1000 rows.\n",
      "Master Dataframe updated to 66352 rows\n",
      "File 78 has 736 rows.\n",
      "Master Dataframe updated to 67088 rows\n",
      "File 79 has 1000 rows.\n",
      "Master Dataframe updated to 68088 rows\n",
      "File 80 has 3159 rows.\n",
      "Master Dataframe updated to 71247 rows\n",
      "File 81 has 1000 rows.\n",
      "Master Dataframe updated to 72247 rows\n",
      "File 82 has 1000 rows.\n",
      "Master Dataframe updated to 73246 rows\n",
      "File 83 has 336 rows.\n",
      "Master Dataframe updated to 73582 rows\n",
      "File 84 has 994 rows.\n",
      "Master Dataframe updated to 74576 rows\n",
      "File 85 has 784 rows.\n",
      "Master Dataframe updated to 75360 rows\n",
      "File 86 has 707 rows.\n",
      "Master Dataframe updated to 76067 rows\n",
      "File 87 has 1000 rows.\n",
      "Master Dataframe updated to 77067 rows\n",
      "File 88 has 997 rows.\n",
      "Master Dataframe updated to 78064 rows\n",
      "File 89 has 1825 rows.\n",
      "Master Dataframe updated to 79889 rows\n",
      "File 90 has 331 rows.\n",
      "Master Dataframe updated to 80218 rows\n",
      "File 91 has 999 rows.\n",
      "Master Dataframe updated to 81217 rows\n",
      "File 92 has 997 rows.\n",
      "Master Dataframe updated to 82214 rows\n",
      "File 93 has 998 rows.\n",
      "Master Dataframe updated to 83212 rows\n",
      "File 94 has 112 rows.\n",
      "Master Dataframe updated to 83324 rows\n",
      "File 95 has 1000 rows.\n",
      "Master Dataframe updated to 84324 rows\n",
      "File 96 has 1000 rows.\n",
      "Master Dataframe updated to 85324 rows\n",
      "File 97 has 1000 rows.\n",
      "Master Dataframe updated to 86324 rows\n",
      "File 98 has 994 rows.\n",
      "Master Dataframe updated to 87318 rows\n",
      "File 99 has 999 rows.\n",
      "Master Dataframe updated to 88317 rows\n",
      "File 100 has 1000 rows.\n",
      "Master Dataframe updated to 89317 rows\n",
      "File 101 has 989 rows.\n",
      "Master Dataframe updated to 90306 rows\n",
      "File 102 has 777 rows.\n",
      "Master Dataframe updated to 91083 rows\n",
      "File 103 has 878 rows.\n",
      "Master Dataframe updated to 91961 rows\n",
      "File 104 has 994 rows.\n",
      "Master Dataframe updated to 92953 rows\n",
      "File 105 has 992 rows.\n",
      "Master Dataframe updated to 93945 rows\n",
      "File 106 has 991 rows.\n",
      "Master Dataframe updated to 94936 rows\n",
      "File 107 has 1000 rows.\n",
      "Master Dataframe updated to 95936 rows\n",
      "File 108 has 98 rows.\n",
      "Master Dataframe updated to 96034 rows\n",
      "File 109 has 999 rows.\n",
      "Master Dataframe updated to 97033 rows\n",
      "File 110 has 995 rows.\n",
      "Master Dataframe updated to 98028 rows\n",
      "File 111 has 953 rows.\n",
      "Master Dataframe updated to 98981 rows\n",
      "File 112 has 13 rows.\n",
      "Master Dataframe updated to 98994 rows\n",
      "File 113 has 1000 rows.\n",
      "Master Dataframe updated to 99994 rows\n",
      "File 114 has 994 rows.\n",
      "Master Dataframe updated to 100988 rows\n",
      "File 115 has 986 rows.\n",
      "Master Dataframe updated to 101974 rows\n",
      "File 116 has 452 rows.\n",
      "Master Dataframe updated to 102426 rows\n",
      "File 117 has 1914 rows.\n",
      "Master Dataframe updated to 104340 rows\n",
      "File 118 has 995 rows.\n",
      "Master Dataframe updated to 105335 rows\n",
      "File 119 has 999 rows.\n",
      "Master Dataframe updated to 106334 rows\n",
      "File 120 has 994 rows.\n",
      "Master Dataframe updated to 107328 rows\n",
      "File 121 has 998 rows.\n",
      "Master Dataframe updated to 108326 rows\n",
      "File 122 has 1260 rows.\n",
      "Master Dataframe updated to 109586 rows\n",
      "File 123 has 1000 rows.\n",
      "Master Dataframe updated to 110586 rows\n",
      "File 124 has 843 rows.\n",
      "Master Dataframe updated to 111429 rows\n",
      "File 125 has 766 rows.\n",
      "Master Dataframe updated to 112195 rows\n",
      "File 126 has 2116 rows.\n",
      "Master Dataframe updated to 114311 rows\n",
      "File 127 has 710 rows.\n",
      "Master Dataframe updated to 115021 rows\n",
      "File 128 has 260 rows.\n",
      "Master Dataframe updated to 115281 rows\n",
      "File 129 has 724 rows.\n",
      "Master Dataframe updated to 116004 rows\n",
      "File 130 has 1000 rows.\n",
      "Master Dataframe updated to 117004 rows\n",
      "File 131 has 696 rows.\n",
      "Master Dataframe updated to 117700 rows\n",
      "File 132 has 71 rows.\n",
      "Master Dataframe updated to 117771 rows\n",
      "File 133 has 994 rows.\n",
      "Master Dataframe updated to 118765 rows\n",
      "File 134 has 471 rows.\n",
      "Master Dataframe updated to 119236 rows\n",
      "File 135 has 999 rows.\n",
      "Master Dataframe updated to 120235 rows\n",
      "File 136 has 999 rows.\n",
      "Master Dataframe updated to 121234 rows\n",
      "File 137 has 1000 rows.\n",
      "Master Dataframe updated to 122234 rows\n",
      "File 138 has 1000 rows.\n",
      "Master Dataframe updated to 123234 rows\n",
      "File 139 has 1000 rows.\n",
      "Master Dataframe updated to 124234 rows\n",
      "File 140 has 989 rows.\n",
      "Master Dataframe updated to 125223 rows\n",
      "File 141 has 1000 rows.\n",
      "Master Dataframe updated to 126223 rows\n",
      "File 142 has 817 rows.\n",
      "Master Dataframe updated to 127040 rows\n",
      "File 143 has 1000 rows.\n",
      "Master Dataframe updated to 128040 rows\n",
      "File 144 has 261 rows.\n",
      "Master Dataframe updated to 128301 rows\n",
      "File 145 has 996 rows.\n",
      "Master Dataframe updated to 129297 rows\n",
      "File 146 has 816 rows.\n",
      "Master Dataframe updated to 130113 rows\n",
      "File 147 has 255 rows.\n",
      "Master Dataframe updated to 130368 rows\n",
      "File 148 has 999 rows.\n",
      "Master Dataframe updated to 131367 rows\n",
      "File 149 has 670 rows.\n",
      "Master Dataframe updated to 132037 rows\n",
      "File 150 has 1000 rows.\n",
      "Master Dataframe updated to 133037 rows\n",
      "File 151 has 997 rows.\n",
      "Master Dataframe updated to 134034 rows\n",
      "File 152 has 386 rows.\n",
      "Master Dataframe updated to 134420 rows\n",
      "File 153 has 1000 rows.\n",
      "Master Dataframe updated to 135420 rows\n",
      "File 154 has 1000 rows.\n",
      "Master Dataframe updated to 136420 rows\n",
      "File 155 has 998 rows.\n",
      "Master Dataframe updated to 137418 rows\n",
      "File 156 has 750 rows.\n",
      "Master Dataframe updated to 138168 rows\n",
      "File 157 has 1000 rows.\n",
      "Master Dataframe updated to 139168 rows\n",
      "File 158 has 1000 rows.\n",
      "Master Dataframe updated to 140168 rows\n",
      "File 159 has 997 rows.\n",
      "Master Dataframe updated to 141165 rows\n",
      "File 160 has 492 rows.\n",
      "Master Dataframe updated to 141657 rows\n",
      "File 161 has 1000 rows.\n",
      "Master Dataframe updated to 142657 rows\n",
      "File 162 has 1000 rows.\n",
      "Master Dataframe updated to 143657 rows\n",
      "File 163 has 994 rows.\n",
      "Master Dataframe updated to 144651 rows\n",
      "File 164 has 1000 rows.\n",
      "Master Dataframe updated to 145651 rows\n",
      "File 165 has 460 rows.\n",
      "Master Dataframe updated to 146111 rows\n",
      "File 166 has 308 rows.\n",
      "Master Dataframe updated to 146419 rows\n",
      "File 167 has 197 rows.\n",
      "Master Dataframe updated to 146616 rows\n",
      "File 168 has 13 rows.\n",
      "Master Dataframe updated to 146629 rows\n",
      "File 169 has 479 rows.\n",
      "Master Dataframe updated to 147108 rows\n",
      "File 170 has 412 rows.\n",
      "Master Dataframe updated to 147520 rows\n",
      "File 171 has 500 rows.\n",
      "Master Dataframe updated to 148020 rows\n",
      "File 172 has 996 rows.\n",
      "Master Dataframe updated to 149016 rows\n",
      "File 173 has 1976 rows.\n",
      "Master Dataframe updated to 150992 rows\n",
      "File 174 has 344 rows.\n",
      "Master Dataframe updated to 151336 rows\n",
      "File 175 has 989 rows.\n",
      "Master Dataframe updated to 152325 rows\n",
      "File 176 has 22 rows.\n",
      "Master Dataframe updated to 152347 rows\n",
      "File 177 has 993 rows.\n",
      "Master Dataframe updated to 153340 rows\n",
      "File 178 has 944 rows.\n",
      "Master Dataframe updated to 154284 rows\n",
      "File 179 has 1000 rows.\n",
      "Master Dataframe updated to 155284 rows\n",
      "File 180 has 649 rows.\n",
      "Master Dataframe updated to 155933 rows\n",
      "File 181 has 1000 rows.\n",
      "Master Dataframe updated to 156933 rows\n",
      "File 182 has 31 rows.\n",
      "Master Dataframe updated to 156964 rows\n",
      "File 183 has 243 rows.\n",
      "Master Dataframe updated to 157207 rows\n",
      "File 184 has 986 rows.\n",
      "Master Dataframe updated to 158193 rows\n",
      "File 185 has 1000 rows.\n",
      "Master Dataframe updated to 159193 rows\n",
      "File 186 has 445 rows.\n",
      "Master Dataframe updated to 159638 rows\n",
      "File 187 has 195 rows.\n",
      "Master Dataframe updated to 159833 rows\n",
      "File 188 has 843 rows.\n",
      "Master Dataframe updated to 160676 rows\n",
      "File 189 has 992 rows.\n",
      "Master Dataframe updated to 161666 rows\n",
      "File 190 has 997 rows.\n",
      "Master Dataframe updated to 162663 rows\n",
      "File 191 has 1000 rows.\n",
      "Master Dataframe updated to 163663 rows\n",
      "File 192 has 125 rows.\n",
      "Master Dataframe updated to 163788 rows\n",
      "File 193 has 11 rows.\n",
      "Master Dataframe updated to 163799 rows\n",
      "File 194 has 561 rows.\n",
      "Master Dataframe updated to 164360 rows\n",
      "File 195 has 890 rows.\n",
      "Master Dataframe updated to 165250 rows\n",
      "File 196 has 986 rows.\n",
      "Master Dataframe updated to 166236 rows\n",
      "File 197 has 998 rows.\n",
      "Master Dataframe updated to 167234 rows\n",
      "File 198 has 997 rows.\n",
      "Master Dataframe updated to 168231 rows\n",
      "File 199 has 315 rows.\n",
      "Master Dataframe updated to 168546 rows\n",
      "File 200 has 1000 rows.\n",
      "Master Dataframe updated to 169546 rows\n",
      "File 201 has 1000 rows.\n",
      "Master Dataframe updated to 170546 rows\n",
      "File 202 has 998 rows.\n",
      "Master Dataframe updated to 171544 rows\n",
      "File 203 has 723 rows.\n",
      "Master Dataframe updated to 172267 rows\n",
      "File 204 has 1000 rows.\n",
      "Master Dataframe updated to 173267 rows\n",
      "File 205 has 989 rows.\n",
      "Master Dataframe updated to 174256 rows\n",
      "File 206 has 996 rows.\n",
      "Master Dataframe updated to 175252 rows\n",
      "File 207 has 1000 rows.\n",
      "Master Dataframe updated to 176252 rows\n",
      "File 208 has 1000 rows.\n",
      "Master Dataframe updated to 177252 rows\n",
      "File 209 has 1000 rows.\n",
      "Master Dataframe updated to 178252 rows\n",
      "File 210 has 1000 rows.\n",
      "Master Dataframe updated to 179252 rows\n",
      "File 211 has 1000 rows.\n",
      "Master Dataframe updated to 180252 rows\n",
      "File 212 has 997 rows.\n",
      "Master Dataframe updated to 181249 rows\n",
      "File 213 has 1000 rows.\n",
      "Master Dataframe updated to 182249 rows\n",
      "File 214 has 92 rows.\n",
      "Master Dataframe updated to 182341 rows\n",
      "File 215 has 26 rows.\n",
      "Master Dataframe updated to 182367 rows\n",
      "File 216 has 1000 rows.\n",
      "Master Dataframe updated to 183367 rows\n",
      "File 217 has 999 rows.\n",
      "Master Dataframe updated to 184366 rows\n",
      "File 218 has 999 rows.\n",
      "Master Dataframe updated to 185365 rows\n",
      "File 219 has 1000 rows.\n",
      "Master Dataframe updated to 186365 rows\n",
      "File 220 has 807 rows.\n",
      "Master Dataframe updated to 187172 rows\n",
      "File 221 has 862 rows.\n",
      "Master Dataframe updated to 188034 rows\n",
      "File 222 has 998 rows.\n",
      "Master Dataframe updated to 189032 rows\n",
      "File 223 has 1000 rows.\n",
      "Master Dataframe updated to 190032 rows\n",
      "File 224 has 984 rows.\n",
      "Master Dataframe updated to 191016 rows\n",
      "File 225 has 1000 rows.\n",
      "Master Dataframe updated to 192016 rows\n",
      "File 226 has 150 rows.\n",
      "Master Dataframe updated to 192166 rows\n",
      "File 227 has 1000 rows.\n",
      "Master Dataframe updated to 193166 rows\n",
      "File 228 has 738 rows.\n",
      "Master Dataframe updated to 193904 rows\n",
      "File 229 has 993 rows.\n",
      "Master Dataframe updated to 194897 rows\n",
      "File 230 has 1000 rows.\n",
      "Master Dataframe updated to 195897 rows\n",
      "File 231 has 999 rows.\n",
      "Master Dataframe updated to 196896 rows\n",
      "File 232 has 998 rows.\n",
      "Master Dataframe updated to 197894 rows\n",
      "File 233 has 122 rows.\n",
      "Master Dataframe updated to 198016 rows\n",
      "File 234 has 993 rows.\n",
      "Master Dataframe updated to 199009 rows\n",
      "File 235 has 148 rows.\n",
      "Master Dataframe updated to 199157 rows\n",
      "File 236 has 964 rows.\n",
      "Master Dataframe updated to 200121 rows\n",
      "File 237 has 879 rows.\n",
      "Master Dataframe updated to 201000 rows\n",
      "File 238 has 1882 rows.\n",
      "Master Dataframe updated to 202882 rows\n",
      "File 239 has 997 rows.\n",
      "Master Dataframe updated to 203879 rows\n",
      "File 240 has 925 rows.\n",
      "Master Dataframe updated to 204804 rows\n",
      "File 241 has 1000 rows.\n",
      "Master Dataframe updated to 205804 rows\n",
      "File 242 has 509 rows.\n",
      "Master Dataframe updated to 206313 rows\n",
      "File 243 has 999 rows.\n",
      "Master Dataframe updated to 207312 rows\n",
      "File 244 has 977 rows.\n",
      "Master Dataframe updated to 208289 rows\n",
      "File 245 has 1000 rows.\n",
      "Master Dataframe updated to 209289 rows\n",
      "File 246 has 119 rows.\n",
      "Master Dataframe updated to 209408 rows\n",
      "File 247 has 999 rows.\n",
      "Master Dataframe updated to 210407 rows\n",
      "File 248 has 1016 rows.\n",
      "Master Dataframe updated to 211423 rows\n",
      "File 249 has 1308 rows.\n",
      "Master Dataframe updated to 212730 rows\n",
      "File 250 has 1000 rows.\n",
      "Master Dataframe updated to 213728 rows\n",
      "File 251 has 660 rows.\n",
      "Master Dataframe updated to 214388 rows\n",
      "File 252 has 1000 rows.\n",
      "Master Dataframe updated to 215388 rows\n",
      "File 253 has 993 rows.\n",
      "Master Dataframe updated to 216381 rows\n",
      "File 254 has 997 rows.\n",
      "Master Dataframe updated to 217378 rows\n",
      "File 255 has 1000 rows.\n",
      "Master Dataframe updated to 218378 rows\n",
      "File 256 has 603 rows.\n",
      "Master Dataframe updated to 218981 rows\n",
      "File 257 has 1000 rows.\n",
      "Master Dataframe updated to 219981 rows\n",
      "File 258 has 25 rows.\n",
      "Master Dataframe updated to 220006 rows\n",
      "File 259 has 914 rows.\n",
      "Master Dataframe updated to 220920 rows\n",
      "File 260 has 523 rows.\n",
      "Master Dataframe updated to 221442 rows\n",
      "File 261 has 212 rows.\n",
      "Master Dataframe updated to 221654 rows\n",
      "File 262 has 999 rows.\n",
      "Master Dataframe updated to 222653 rows\n",
      "File 263 has 998 rows.\n",
      "Master Dataframe updated to 223651 rows\n",
      "File 264 has 725 rows.\n",
      "Master Dataframe updated to 224376 rows\n",
      "File 265 has 995 rows.\n",
      "Master Dataframe updated to 225371 rows\n",
      "File 266 has 995 rows.\n",
      "Master Dataframe updated to 226366 rows\n",
      "File 267 has 967 rows.\n",
      "Master Dataframe updated to 227333 rows\n",
      "File 268 has 976 rows.\n",
      "Master Dataframe updated to 228309 rows\n",
      "File 269 has 998 rows.\n",
      "Master Dataframe updated to 229304 rows\n",
      "File 270 has 993 rows.\n",
      "Master Dataframe updated to 230297 rows\n",
      "File 271 has 723 rows.\n",
      "Master Dataframe updated to 231020 rows\n",
      "File 272 has 955 rows.\n",
      "Master Dataframe updated to 231975 rows\n",
      "File 273 has 991 rows.\n",
      "Master Dataframe updated to 232966 rows\n",
      "File 274 has 990 rows.\n",
      "Master Dataframe updated to 233956 rows\n",
      "File 275 has 1000 rows.\n",
      "Master Dataframe updated to 234956 rows\n",
      "File 276 has 1878 rows.\n",
      "Master Dataframe updated to 236834 rows\n",
      "File 277 has 1000 rows.\n",
      "Master Dataframe updated to 237831 rows\n",
      "File 278 has 1000 rows.\n",
      "Master Dataframe updated to 238830 rows\n",
      "File 279 has 1000 rows.\n",
      "Master Dataframe updated to 239830 rows\n",
      "File 280 has 994 rows.\n",
      "Master Dataframe updated to 240824 rows\n",
      "File 281 has 1953 rows.\n",
      "Master Dataframe updated to 242777 rows\n",
      "File 282 has 994 rows.\n",
      "Master Dataframe updated to 243770 rows\n",
      "File 283 has 991 rows.\n",
      "Master Dataframe updated to 244761 rows\n",
      "File 284 has 888 rows.\n",
      "Master Dataframe updated to 245649 rows\n",
      "File 285 has 496 rows.\n",
      "Master Dataframe updated to 246145 rows\n",
      "File 286 has 2656 rows.\n",
      "Master Dataframe updated to 248801 rows\n",
      "File 287 has 592 rows.\n",
      "Master Dataframe updated to 249393 rows\n",
      "File 288 has 1000 rows.\n",
      "Master Dataframe updated to 250393 rows\n",
      "File 289 has 993 rows.\n",
      "Master Dataframe updated to 251384 rows\n",
      "File 290 has 1000 rows.\n",
      "Master Dataframe updated to 252384 rows\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252384 entries, 0 to 252383\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   end_station_name    252384 non-null  object \n",
      " 1   end_lng             252384 non-null  float64\n",
      " 2   started_at          252384 non-null  object \n",
      " 3   start_lat           252384 non-null  float64\n",
      " 4   end_station_id      252384 non-null  object \n",
      " 5   ended_at            252384 non-null  object \n",
      " 6   start_station_id    252384 non-null  object \n",
      " 7   end_lat             252384 non-null  float64\n",
      " 8   start_station_name  252384 non-null  object \n",
      " 9   member_casual       252384 non-null  object \n",
      " 10  start_lng           252384 non-null  float64\n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 21.2+ MB\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "master_df = append_my_files(all_files, col_translation= col_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e3c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252384 entries, 0 to 252383\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   end_station_name    252384 non-null  object \n",
      " 1   end_lng             252384 non-null  float64\n",
      " 2   started_at          252384 non-null  object \n",
      " 3   start_lat           252384 non-null  float64\n",
      " 4   end_station_id      252384 non-null  object \n",
      " 5   ended_at            252384 non-null  object \n",
      " 6   start_station_id    252384 non-null  object \n",
      " 7   end_lat             252384 non-null  float64\n",
      " 8   start_station_name  252384 non-null  object \n",
      " 9   member_casual       252384 non-null  object \n",
      " 10  start_lng           252384 non-null  float64\n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 21.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#further cleaning \n",
    "master_df.head()\n",
    "master_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5ce0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "if not os.path.exists('output'): os.mkdir('output')\n",
    "master_df.to_csv('output/master_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbc3598",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "All the above took a while to run, so lets use this opportunity to \"reset\". I am going to pull in the intermediate file I saved in the previous step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "276ae470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stuff we need\n",
    "import os \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ccaf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252384 entries, 0 to 252383\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Unnamed: 0          252384 non-null  int64  \n",
      " 1   end_station_name    252384 non-null  object \n",
      " 2   end_lng             252384 non-null  float64\n",
      " 3   started_at          252384 non-null  object \n",
      " 4   start_lat           252384 non-null  float64\n",
      " 5   end_station_id      252384 non-null  object \n",
      " 6   ended_at            252384 non-null  object \n",
      " 7   start_station_id    252384 non-null  object \n",
      " 8   end_lat             252384 non-null  float64\n",
      " 9   start_station_name  252384 non-null  object \n",
      " 10  member_casual       252384 non-null  object \n",
      " 11  start_lng           252384 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 23.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>start_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>252384.000000</td>\n",
       "      <td>252384.000000</td>\n",
       "      <td>252384.000000</td>\n",
       "      <td>252384.000000</td>\n",
       "      <td>252384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>126191.500000</td>\n",
       "      <td>-73.977045</td>\n",
       "      <td>40.738547</td>\n",
       "      <td>40.738175</td>\n",
       "      <td>-73.977165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72857.129507</td>\n",
       "      <td>0.149331</td>\n",
       "      <td>0.036084</td>\n",
       "      <td>0.088710</td>\n",
       "      <td>0.024786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.038051</td>\n",
       "      <td>40.602580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.027472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63095.750000</td>\n",
       "      <td>-73.994224</td>\n",
       "      <td>40.716059</td>\n",
       "      <td>40.716059</td>\n",
       "      <td>-73.994156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>126191.500000</td>\n",
       "      <td>-73.982666</td>\n",
       "      <td>40.738177</td>\n",
       "      <td>40.737815</td>\n",
       "      <td>-73.982582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>189287.250000</td>\n",
       "      <td>-73.962658</td>\n",
       "      <td>40.760301</td>\n",
       "      <td>40.760193</td>\n",
       "      <td>-73.962868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>252383.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.886300</td>\n",
       "      <td>40.886300</td>\n",
       "      <td>-73.846720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0        end_lng      start_lat        end_lat  \\\n",
       "count  252384.000000  252384.000000  252384.000000  252384.000000   \n",
       "mean   126191.500000     -73.977045      40.738547      40.738175   \n",
       "std     72857.129507       0.149331       0.036084       0.088710   \n",
       "min         0.000000     -74.038051      40.602580       0.000000   \n",
       "25%     63095.750000     -73.994224      40.716059      40.716059   \n",
       "50%    126191.500000     -73.982666      40.738177      40.737815   \n",
       "75%    189287.250000     -73.962658      40.760301      40.760193   \n",
       "max    252383.000000       0.000000      40.886300      40.886300   \n",
       "\n",
       "           start_lng  \n",
       "count  252384.000000  \n",
       "mean      -73.977165  \n",
       "std         0.024786  \n",
       "min       -74.027472  \n",
       "25%       -73.994156  \n",
       "50%       -73.982582  \n",
       "75%       -73.962868  \n",
       "max       -73.846720  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "master_df = pd.read_csv('data/output/master_df.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c51ca0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252384 entries, 0 to 252383\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Unnamed: 0          252384 non-null  int64  \n",
      " 1   end_station_name    252384 non-null  object \n",
      " 2   end_lng             252384 non-null  float64\n",
      " 3   started_at          252384 non-null  object \n",
      " 4   start_lat           252384 non-null  float64\n",
      " 5   end_station_id      252384 non-null  object \n",
      " 6   ended_at            252384 non-null  object \n",
      " 7   start_station_id    252384 non-null  object \n",
      " 8   end_lat             252384 non-null  float64\n",
      " 9   start_station_name  252384 non-null  object \n",
      " 10  member_casual       252384 non-null  object \n",
      " 11  start_lng           252384 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 23.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>started_at</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>start_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DeKalb Ave &amp; Hudson Ave</td>\n",
       "      <td>-73.981013</td>\n",
       "      <td>2017-06-09 11:56:59</td>\n",
       "      <td>40.695128</td>\n",
       "      <td>324</td>\n",
       "      <td>2017-06-09 12:15:24</td>\n",
       "      <td>406</td>\n",
       "      <td>40.689888</td>\n",
       "      <td>Hicks St &amp; Montague St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>-73.995951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pershing Square North</td>\n",
       "      <td>-73.977706</td>\n",
       "      <td>2017-06-05 17:32:02</td>\n",
       "      <td>40.703554</td>\n",
       "      <td>519</td>\n",
       "      <td>2017-06-05 18:03:40</td>\n",
       "      <td>315</td>\n",
       "      <td>40.751873</td>\n",
       "      <td>South St &amp; Gouverneur Ln</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>-74.006702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E 39 St &amp; 2 Ave</td>\n",
       "      <td>-73.973442</td>\n",
       "      <td>2017-06-02 16:20:13</td>\n",
       "      <td>40.740964</td>\n",
       "      <td>518</td>\n",
       "      <td>2017-06-02 16:29:07</td>\n",
       "      <td>491</td>\n",
       "      <td>40.747804</td>\n",
       "      <td>E 24 St &amp; Park Ave S</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>-73.986022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>E 81 St &amp; 3 Ave</td>\n",
       "      <td>-73.956753</td>\n",
       "      <td>2017-06-14 20:25:24</td>\n",
       "      <td>40.764719</td>\n",
       "      <td>3146</td>\n",
       "      <td>2017-06-14 20:32:28</td>\n",
       "      <td>3376</td>\n",
       "      <td>40.775730</td>\n",
       "      <td>E 65 St &amp; 2 Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>-73.962221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Broadway &amp; W 60 St</td>\n",
       "      <td>-73.981918</td>\n",
       "      <td>2017-06-06 19:01:25</td>\n",
       "      <td>40.744876</td>\n",
       "      <td>499</td>\n",
       "      <td>2017-06-06 19:26:02</td>\n",
       "      <td>446</td>\n",
       "      <td>40.769155</td>\n",
       "      <td>W 24 St &amp; 7 Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>-73.995299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         end_station_name    end_lng           started_at  \\\n",
       "0           0  DeKalb Ave & Hudson Ave -73.981013  2017-06-09 11:56:59   \n",
       "1           1    Pershing Square North -73.977706  2017-06-05 17:32:02   \n",
       "2           2          E 39 St & 2 Ave -73.973442  2017-06-02 16:20:13   \n",
       "3           3          E 81 St & 3 Ave -73.956753  2017-06-14 20:25:24   \n",
       "4           4       Broadway & W 60 St -73.981918  2017-06-06 19:01:25   \n",
       "\n",
       "   start_lat end_station_id             ended_at start_station_id    end_lat  \\\n",
       "0  40.695128            324  2017-06-09 12:15:24              406  40.689888   \n",
       "1  40.703554            519  2017-06-05 18:03:40              315  40.751873   \n",
       "2  40.740964            518  2017-06-02 16:29:07              491  40.747804   \n",
       "3  40.764719           3146  2017-06-14 20:32:28             3376  40.775730   \n",
       "4  40.744876            499  2017-06-06 19:26:02              446  40.769155   \n",
       "\n",
       "         start_station_name member_casual  start_lng  \n",
       "0    Hicks St & Montague St      Customer -73.995951  \n",
       "1  South St & Gouverneur Ln    Subscriber -74.006702  \n",
       "2      E 24 St & Park Ave S    Subscriber -73.986022  \n",
       "3           E 65 St & 2 Ave    Subscriber -73.962221  \n",
       "4           W 24 St & 7 Ave    Subscriber -73.995299  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.info()\n",
    "master_df.describe()\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a913f6",
   "metadata": {},
   "source": [
    "### Converting Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date time needs to be converted for started_at and ended_at\n",
    "df_clean = master_df.copy()\n",
    "df_clean = df_clean['started_at'].to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4cc081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
